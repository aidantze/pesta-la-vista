{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkKXfICEZvZVFoUnyKbaoA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aidantze/pesta-la-vista/blob/ml_models/ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Models\n",
        "9517 Group Assignment"
      ],
      "metadata": {
        "id": "opIMolq4bNlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constants"
      ],
      "metadata": {
        "id": "YAGFwJFMaEMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN constants\n",
        "RESOLUTION = 64                  # default 512, CPU limits us to no higher than 64 without crashing\n",
        "K_NEIGHBORS = 5                   # default 5\n",
        "\n",
        "# Noise and filter constants\n",
        "APPLY_CORRUPTION = False\n",
        "CORRUPT_TYPE = 'gaussian_noise'   # one of: 'gaussian_noise', 'salt_pepper_noise', 'gaussian_blur'\n",
        "CORRUPT_STRENGTH = 0.05           # e.g., 0.05 = 5% noise or 5x5 kernel blur"
      ],
      "metadata": {
        "id": "HlD-ljheZq9_"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup (Do Not Change)"
      ],
      "metadata": {
        "id": "M022Oz4xaHL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kagglehub pyyaml\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import kagglehub\n",
        "import pathlib\n",
        "import yaml\n",
        "import shutil\n",
        "import os\n",
        "import time\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import torch\n",
        "\n",
        "# Check for T4 availability on Colab (DON'T CHANGE)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU detected. Go to Runtime -> Change runtime type ->  GPU\")\n",
        "\n",
        "# Kaggle Download via CLI API (see their website - DON'T CHANGE)\n",
        "path = kagglehub.dataset_download(\"rupankarmajumdar/crop-pests-dataset\")\n",
        "\n",
        "# Saved the images to a local path to increase efficiency\n",
        "local_path = pathlib.Path(\"/content/datasets/crop-pests\")\n",
        "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "shutil.copytree(path, local_path, dirs_exist_ok=True)\n",
        "\n",
        "# YAML CONGIF (DON'T CHANGE)\n",
        "data_yaml_path = local_path / \"data.yaml\"\n",
        "data_cfg = {\n",
        "    \"path\": str(local_path),\n",
        "    \"train\": \"train/images\",\n",
        "    \"val\":   \"valid/images\",\n",
        "    \"test\":  \"test/images\",\n",
        "    \"names\": [\n",
        "        \"ant\", \"bee\", \"beetle\", \"caterpillar\", \"earthworm\", \"earwig\",\n",
        "        \"grasshopper\", \"moth\", \"slug\", \"snail\", \"wasp\", \"weevil\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    yaml.safe_dump(data_cfg, f)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk1KaTwOaILg",
        "outputId": "e5136259-b190-4e86-d5b0-cccbd5bb837a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Operation cancelled by user\u001b[0m\u001b[31m\n",
            "\u001b[0mCUDA available: False\n",
            "No GPU detected. Go to Runtime -> Change runtime type ->  GPU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading Function for KNN\n",
        "CLASS_NAMES = data_cfg[\"names\"]\n",
        "CLASS_MAP = {name: i for i, name in enumerate(CLASS_NAMES)}\n",
        "\n",
        "def load_split_data(base_path, split_name, class_map, img_size):\n",
        "    \"\"\"\n",
        "    Loads images and extracts the majority class label from the YOLO-style\n",
        "    label files for KNN classification.\n",
        "    \"\"\"\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "\n",
        "    split_dir = base_path / split_name\n",
        "    image_dir = split_dir / \"images\"\n",
        "    label_dir = split_dir / \"labels\"\n",
        "\n",
        "    print(f\"\\nProcessing images in: {image_dir}\")\n",
        "\n",
        "    if not image_dir.exists() or not label_dir.exists():\n",
        "        print(f\"Error: Could not find 'images' or 'labels' in {split_dir}\")\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    for img_file in image_dir.glob(\"*.jpg\"):\n",
        "\n",
        "        # 1. Determine the corresponding label file name (.txt)\n",
        "        label_file = label_dir / (img_file.stem + \".txt\")\n",
        "\n",
        "        # 2. Check and process label file\n",
        "        if not label_file.exists():\n",
        "            # print(f\"Warning: Missing label file for {img_file.name}\") # Too verbose\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Read all lines from the label file\n",
        "            with open(label_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            if not lines:\n",
        "                continue # Skip if label file is empty\n",
        "\n",
        "            # Extract all class IDs (the first number in each row)\n",
        "            class_ids = [int(line.strip().split()[0]) for line in lines]\n",
        "\n",
        "            # Find the majority class ID (the most frequent insect)\n",
        "            # bincount is efficient for finding frequencies of non-negative integers\n",
        "            class_counts = np.bincount(class_ids)\n",
        "            majority_class_id = np.argmax(class_counts)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading label {label_file.name}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # 3. Load and Preprocess Image\n",
        "        # Load as color image (3 channels) for consistent feature count\n",
        "        img = cv2.imread(str(img_file), cv2.IMREAD_COLOR)\n",
        "\n",
        "        if img is not None:\n",
        "            # Resize, flatten, and normalize\n",
        "            img = cv2.resize(img, (img_size, img_size))\n",
        "            img_normalized = img.astype('float32') / 255.0\n",
        "\n",
        "            X_list.append(img_normalized.flatten())\n",
        "            y_list.append(majority_class_id) # Use the derived majority class\n",
        "\n",
        "    # 4. Final array creation (handles the 2D shape requirement)\n",
        "    X = np.array(X_list, dtype='float32')\n",
        "    y = np.array(y_list)\n",
        "\n",
        "    print(f\"Loaded {len(X)} samples for {split_name}. Final shape: {X.shape}\")\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "l8zo0YMDkvr5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noise and Filter Analysis"
      ],
      "metadata": {
        "id": "fjEM2WtaaQT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_corruption_to_folder(source_dir, destination_dir, corruption_type, strength=0.01):\n",
        "    \"\"\"\n",
        "    Copies images from source to destination and applies a specified corruption.\n",
        "    (Function body is omitted here for brevity, assuming the user's provided code is used)\n",
        "    \"\"\"\n",
        "    if destination_dir.exists():\n",
        "        shutil.rmtree(destination_dir)\n",
        "    shutil.copytree(source_dir, destination_dir)\n",
        "\n",
        "    if corruption_type == 'gaussian_noise':\n",
        "        sigma = int(strength * 255)\n",
        "        print(f\"\\nApplying {corruption_type} (Sigma: {sigma}) to images in {destination_dir.name}...\")\n",
        "        for img_file in destination_dir.glob('*.jpg'):\n",
        "            img = cv2.imread(str(img_file))\n",
        "            if img is None: continue\n",
        "            noise = np.random.normal(0, sigma, img.shape).astype('uint8')\n",
        "            corrupted_img = cv2.add(img, noise)\n",
        "            cv2.imwrite(str(img_file), corrupted_img)\n",
        "\n",
        "    elif corruption_type == 'salt_pepper_noise':\n",
        "        ratio = strength\n",
        "        print(f\"\\nApplying {corruption_type} (Ratio: {ratio}) to images in {destination_dir.name}...\")\n",
        "        for img_file in destination_dir.glob('*.jpg'):\n",
        "            img = cv2.imread(str(img_file))\n",
        "            if img is None: continue\n",
        "            corrupted_img = img.copy()\n",
        "            total_pixels = img.size\n",
        "\n",
        "            # TODO: verify the logic of this part, it seems the img coords is always pepper (0)\n",
        "            # num_salt_pepper = int(ratio * total_pixels / img.shape[2])\n",
        "            # coords = [np.random.randint(0, i - 1, num_salt_pepper) for i in img.shape]\n",
        "            # corrupted_img[coords[0], coords[1], coords[2]] = 255\n",
        "            # coords = [np.random.randint(0, i - 1, num_salt_pepper) for i in img.shape]\n",
        "            # corrupted_img[coords[0], coords[1], coords[2]] = 0\n",
        "            # cv2.imwrite(str(img_file), corrupted_img)\n",
        "\n",
        "\n",
        "            num_corrupt_elements = int(ratio * total_pixels)\n",
        "            flat_indices = np.random.choice(\n",
        "                total_pixels,\n",
        "                size=num_corrupt_elements,\n",
        "                replace=False\n",
        "            )\n",
        "            num_salt = num_pepper = num_corrupt_elements // 2\n",
        "\n",
        "            # Apply Salt (White)\n",
        "            salt_indices = flat_indices[:num_salt]\n",
        "            corrupted_img.flat[salt_indices] = 255\n",
        "\n",
        "            # Apply Pepper (Black)\n",
        "            pepper_indices = flat_indices[num_salt:num_salt + num_pepper]\n",
        "            corrupted_img.flat[pepper_indices] = 0\n",
        "\n",
        "    elif corruption_type == 'gaussian_blur':\n",
        "        ksize = int(strength * 100) if int(strength * 100) % 2 != 0 else int(strength * 100) + 1\n",
        "        print(f\"\\nApplying {corruption_type} (ksize: {ksize}) to images in {destination_dir.name}...\")\n",
        "        for img_file in destination_dir.glob('*.jpg'):\n",
        "            img = cv2.imread(str(img_file))\n",
        "            if img is None: continue\n",
        "            corrupted_img = cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
        "            cv2.imwrite(str(img_file), corrupted_img)\n",
        "\n",
        "    print(\"Corruption application complete.\")\n",
        "\n",
        "\n",
        "VAL_DIR_NAME = \"valid\"\n",
        "if APPLY_CORRUPTION:\n",
        "    original_val_path = local_path / VAL_DIR_NAME\n",
        "    corrupt_val_path_name = f\"{VAL_DIR_NAME}_corrupted\"\n",
        "    corrupt_val_path = local_path / corrupt_val_path_name\n",
        "\n",
        "    # Create the corrupted validation set by copying and modifying the 'valid' split\n",
        "    apply_corruption_to_folder(\n",
        "        original_val_path,\n",
        "        corrupt_val_path,\n",
        "        CORRUPT_TYPE,\n",
        "        CORRUPT_STRENGTH\n",
        "    )\n",
        "    VAL_DIR_NAME = corrupt_val_path_name # Switch the validation directory name"
      ],
      "metadata": {
        "id": "-QCrLSKbaSqU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data Splits"
      ],
      "metadata": {
        "id": "LiJYeVN0aW1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Load Data Splits ---\n",
        "X_train, y_train = load_split_data(local_path, \"train\", CLASS_MAP, RESOLUTION)\n",
        "\n",
        "# Load validation data (clean or corrupted)\n",
        "X_val, y_val = load_split_data(local_path, VAL_DIR_NAME, CLASS_MAP, RESOLUTION)\n",
        "\n",
        "# Load test data\n",
        "X_test, y_test = load_split_data(local_path, \"test\", CLASS_MAP, RESOLUTION)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H1ZJQY9aYKs",
        "outputId": "2e974af1-49e8-4057-e9d8-b5eb8e07555c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing images in: /content/datasets/crop-pests/train/images\n",
            "Loaded 11499 samples for train. Final shape: (11499, 12288)\n",
            "\n",
            "Processing images in: /content/datasets/crop-pests/valid/images\n",
            "Loaded 1095 samples for valid. Final shape: (1095, 12288)\n",
            "\n",
            "Processing images in: /content/datasets/crop-pests/test/images\n",
            "Loaded 546 samples for test. Final shape: (546, 12288)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# format time for metrics in next stage\n",
        "def format_time(seconds):\n",
        "    \"\"\"Converts total seconds into minutes and seconds format.\"\"\"\n",
        "    # Ensure all time variables (train_time, val_time, test_time) are available\n",
        "    mins, secs = divmod(seconds, 60)\n",
        "    return f\"{int(mins):0d}m {secs:.2f}s\""
      ],
      "metadata": {
        "id": "KeJd7_PM_WuB"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN Classifier — Train model, prediction and evaluation"
      ],
      "metadata": {
        "id": "C6OKAJK2acIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Model\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=K_NEIGHBORS)\n",
        "\n",
        "start = time.time()\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "knn_train_time = end - start\n",
        "\n",
        "start_kernel = time.time()\n",
        "knn_val_pred = knn_classifier.predict(X_val)\n",
        "end = time.time()\n",
        "knn_val_time = end - start\n",
        "\n",
        "knn_val_probas = knn_classifier.predict_proba(X_val)\n",
        "\n",
        "start = time.time()\n",
        "knn_test_pred = knn_classifier.predict(X_test)\n",
        "end = time.time()\n",
        "knn_test_time = end - start\n"
      ],
      "metadata": {
        "id": "_PPB92IEailE"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics\n",
        "# We use the 'weighted' average suitable for multi-class, potentially imbalanced data.\n",
        "accuracy = metrics.accuracy_score(y_val, knn_val_pred)\n",
        "precision, recall, f1_score, _ = metrics.precision_recall_fscore_support(\n",
        "    y_val, knn_val_pred, average='weighted', zero_division=0\n",
        ")\n",
        "\n",
        "# AUC is calculated in a One-vs-Rest fashion for multi-class problems.\n",
        "# The true labels (y_val) must be binarized first.\n",
        "lb = LabelBinarizer()\n",
        "y_val_binarized = lb.fit_transform(y_val)\n",
        "\n",
        "# We use the 'weighted' average to account for class support\n",
        "auc_score = metrics.roc_auc_score(\n",
        "    y_val_binarized,\n",
        "    knn_val_probas,\n",
        "    average='weighted',\n",
        "    multi_class='ovr'\n",
        ")\n",
        "\n",
        "# --- 4. Output Refactored Metrics ---\n",
        "print(f\"Results for KNN (K={K_NEIGHBORS}) with image size {RESOLUTION} and {f\"{CORRUPT_TYPE}, strength set to {CORRUPT_STRENGTH}\" if APPLY_CORRUPTION else \"no filters\"}:\\n\")\n",
        "\n",
        "# NOTE: mAP is not available for KNN (Classification)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision (Weighted): {precision:.4f}\")\n",
        "print(f\"Recall (Weighted): {recall:.4f}\")\n",
        "print(f\"F1-Score (Weighted): {f1_score:.4f}\")\n",
        "print(f\"Area Under the Curve (AUC): {auc_score:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining Time (Total): {format_time(knn_train_time)}\")\n",
        "print(f\"Validation Time (Prediction): {format_time(knn_val_time)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU32-Ylor7Lr",
        "outputId": "296dc9ac-4987-41ee-d24f-c5689234d9d7"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for KNN (K=5) with image size 64 and no filters:\n",
            "\n",
            "Accuracy: 0.1653\n",
            "Precision (Weighted): 0.1874\n",
            "Recall (Weighted): 0.1653\n",
            "F1-Score (Weighted): 0.1505\n",
            "Area Under the Curve (AUC): 0.5918\n",
            "\n",
            "Training Time (Total): 0m 0.46s\n",
            "Validation Time (Prediction): 0m 15.47s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Classifier — Train model, prediction and evaluation"
      ],
      "metadata": {
        "id": "SgoAVtCs1Vqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "start = time.time()\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "dt_train_time = end - start\n",
        "\n",
        "start_kernel = time.time()\n",
        "dt_val_pred = dt_classifier.predict(X_val)\n",
        "end = time.time()\n",
        "dt_val_time = end - start\n",
        "\n",
        "dt_val_probas = dt_classifier.predict_proba(X_val)\n",
        "\n",
        "start = time.time()\n",
        "dt_test_pred = dt_classifier.predict(X_test)\n",
        "end = time.time()\n",
        "dt_test_time = end - start"
      ],
      "metadata": {
        "id": "_7Cfov6a1XYe"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics\n",
        "# We use the 'weighted' average suitable for multi-class, potentially imbalanced data.\n",
        "accuracy = metrics.accuracy_score(y_val, dt_val_pred)\n",
        "precision, recall, f1_score, _ = metrics.precision_recall_fscore_support(\n",
        "    y_val, dt_val_pred, average='weighted', zero_division=0\n",
        ")\n",
        "\n",
        "# AUC is calculated in a One-vs-Rest fashion for multi-class problems.\n",
        "# The true labels (y_val) must be binarized first.\n",
        "lb = LabelBinarizer()\n",
        "y_val_binarized = lb.fit_transform(y_val)\n",
        "\n",
        "# We use the 'weighted' average to account for class support\n",
        "auc_score = metrics.roc_auc_score(\n",
        "    y_val_binarized,\n",
        "    dt_val_probas,\n",
        "    average='weighted',\n",
        "    multi_class='ovr'\n",
        ")\n",
        "\n",
        "\n",
        "# --- 4. Output Refactored Metrics ---\n",
        "print(f\"Results for DT with image size {RESOLUTION} and {f\"{CORRUPT_TYPE}, strength set to {CORRUPT_STRENGTH}\" if APPLY_CORRUPTION else \"no filters\"}:\\n\")\n",
        "\n",
        "# NOTE: mAP is not available for KNN (Classification)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision (Weighted): {precision:.4f}\")\n",
        "print(f\"Recall (Weighted): {recall:.4f}\")\n",
        "print(f\"F1-Score (Weighted): {f1_score:.4f}\")\n",
        "print(f\"Area Under the Curve (AUC): {auc_score:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining Time (Total): {format_time(dt_train_time)}\")\n",
        "print(f\"Validation Time (Prediction): {format_time(dt_val_time)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNoj_NrD1XqA",
        "outputId": "69e90614-5119-422a-a1dd-a7d1fe522bbc"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for DT with image size 64 and no filters:\n",
            "\n",
            "Accuracy: 0.1260\n",
            "Precision (Weighted): 0.1252\n",
            "Recall (Weighted): 0.1260\n",
            "F1-Score (Weighted): 0.1252\n",
            "Area Under the Curve (AUC): 0.5226\n",
            "\n",
            "Training Time (Total): 4m 56.24s\n",
            "Validation Time (Prediction): 4m 56.24s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD Classifier — Train model, prediction and evaluation"
      ],
      "metadata": {
        "id": "p3w6utSW1ZUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_classifier = SGDClassifier(loss='log_loss', max_iter=250, random_state=42)\n",
        "\n",
        "start = time.time()\n",
        "sgd_classifier.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "sgd_train_time = end - start\n",
        "\n",
        "start = time.time()\n",
        "sgd_val_pred = sgd_classifier.predict(X_val)\n",
        "end = time.time()\n",
        "sgd_val_time = end - start\n",
        "\n",
        "sgd_val_probas = sgd_classifier.predict_proba(X_val)\n",
        "\n",
        "start = time.time()\n",
        "sgd_test_pred = sgd_classifier.predict(X_test)\n",
        "end = time.time()\n",
        "sgd_test_time = end - start"
      ],
      "metadata": {
        "id": "qnKFjyFj1cc4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics\n",
        "# We use the 'weighted' average suitable for multi-class, potentially imbalanced data.\n",
        "accuracy = metrics.accuracy_score(y_val, sgd_val_pred)\n",
        "precision, recall, f1_score, _ = metrics.precision_recall_fscore_support(\n",
        "    y_val, sgd_val_pred, average='weighted', zero_division=0\n",
        ")\n",
        "\n",
        "# AUC is calculated in a One-vs-Rest fashion for multi-class problems.\n",
        "# The true labels (y_val) must be binarized first.\n",
        "lb = LabelBinarizer()\n",
        "y_val_binarized = lb.fit_transform(y_val)\n",
        "\n",
        "# We use the 'weighted' average to account for class support\n",
        "auc_score = metrics.roc_auc_score(\n",
        "    y_val_binarized,\n",
        "    sgd_val_probas,\n",
        "    average='weighted',\n",
        "    multi_class='ovr'\n",
        ")\n",
        "\n",
        "\n",
        "# --- 4. Output Refactored Metrics ---\n",
        "print(f\"Results for SGD with image size {RESOLUTION} and {f\"{CORRUPT_TYPE}, strength set to {CORRUPT_STRENGTH}\" if APPLY_CORRUPTION else \"no filters\"}:\\n\")\n",
        "\n",
        "# NOTE: mAP is not available for KNN (Classification)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision (Weighted): {precision:.4f}\")\n",
        "print(f\"Recall (Weighted): {recall:.4f}\")\n",
        "print(f\"F1-Score (Weighted): {f1_score:.4f}\")\n",
        "print(f\"Area Under the Curve (AUC): {auc_score:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining Time (Total): {format_time(sgd_train_time)}\")\n",
        "print(f\"Validation Time (Prediction): {format_time(sgd_val_time)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZhRmHvl1crl",
        "outputId": "48b83b28-265f-4b8a-b53a-3dd0e9f0a14a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for SGD with image size 64 and no filters:\n",
            "\n",
            "Accuracy: 0.1562\n",
            "Precision (Weighted): 0.1513\n",
            "Recall (Weighted): 0.1562\n",
            "F1-Score (Weighted): 0.1481\n",
            "Area Under the Curve (AUC): 0.6069\n",
            "\n",
            "Training Time (Total): 14m 57.31s\n",
            "Validation Time (Prediction): 0m 0.02s\n"
          ]
        }
      ]
    }
  ]
}