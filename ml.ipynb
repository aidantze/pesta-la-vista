{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMvR4dV1uU1mQUtRbarq3ms",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aidantze/pesta-la-vista/blob/ml_models/ml.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ML Models\n",
        "9517 Group Assignment"
      ],
      "metadata": {
        "id": "opIMolq4bNlJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constants"
      ],
      "metadata": {
        "id": "YAGFwJFMaEMe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# KNN constants\n",
        "RESOLUTION = 64                  # default 512, CPU limits us to no higher than 64 without crashing\n",
        "K_NEIGHBORS = 5                   # default 5\n",
        "\n",
        "# Noise and filter constants\n",
        "APPLY_CORRUPTION = True\n",
        "CORRUPT_TYPE = 'gaussian_blur'   # one of: 'gaussian_noise', 'salt_pepper_noise', 'gaussian_blur'\n",
        "CORRUPT_STRENGTH = 0.05           # e.g., 0.05 = 5% noise or 5x5 kernel blur"
      ],
      "metadata": {
        "id": "HlD-ljheZq9_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup (Do Not Change)"
      ],
      "metadata": {
        "id": "M022Oz4xaHL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kagglehub pyyaml\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import kagglehub\n",
        "import pathlib\n",
        "import yaml\n",
        "import shutil\n",
        "import os\n",
        "import time\n",
        "\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "import torch\n",
        "\n",
        "# Check for T4 availability on Colab (DON'T CHANGE)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU detected. Go to Runtime -> Change runtime type ->  GPU\")\n",
        "\n",
        "# Kaggle Download via CLI API (see their website - DON'T CHANGE)\n",
        "path = kagglehub.dataset_download(\"rupankarmajumdar/crop-pests-dataset\")\n",
        "\n",
        "# Saved the images to a local path to increase efficiency\n",
        "local_path = pathlib.Path(\"/content/datasets/crop-pests\")\n",
        "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "shutil.copytree(path, local_path, dirs_exist_ok=True)\n",
        "\n",
        "# YAML CONGIF (DON'T CHANGE)\n",
        "data_yaml_path = local_path / \"data.yaml\"\n",
        "data_cfg = {\n",
        "    \"path\": str(local_path),\n",
        "    \"train\": \"train/images\",\n",
        "    \"val\":   \"valid/images\",\n",
        "    \"test\":  \"test/images\",\n",
        "    \"names\": [\n",
        "        \"ant\", \"bee\", \"beetle\", \"caterpillar\", \"earthworm\", \"earwig\",\n",
        "        \"grasshopper\", \"moth\", \"slug\", \"snail\", \"wasp\", \"weevil\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    yaml.safe_dump(data_cfg, f)\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk1KaTwOaILg",
        "outputId": "4fd0835a-cd69-484c-db35-3394d06f8a04"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA available: False\n",
            "No GPU detected. Go to Runtime -> Change runtime type ->  GPU\n",
            "Using Colab cache for faster access to the 'crop-pests-dataset' dataset.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Loading Function for KNN\n",
        "CLASS_NAMES = data_cfg[\"names\"]\n",
        "CLASS_MAP = {name: i for i, name in enumerate(CLASS_NAMES)}\n",
        "\n",
        "def load_split_data(base_path, split_name, class_map, img_size):\n",
        "    \"\"\"\n",
        "    Loads images and extracts the majority class label from the YOLO-style\n",
        "    label files for KNN classification.\n",
        "    \"\"\"\n",
        "    X_list = []\n",
        "    y_list = []\n",
        "\n",
        "    split_dir = base_path / split_name\n",
        "    image_dir = split_dir / \"images\"\n",
        "    label_dir = split_dir / \"labels\"\n",
        "\n",
        "    print(f\"\\nProcessing images in: {image_dir}\")\n",
        "\n",
        "    if not image_dir.exists() or not label_dir.exists():\n",
        "        print(f\"Error: Could not find 'images' or 'labels' in {split_dir}\")\n",
        "        return np.array([]), np.array([])\n",
        "\n",
        "    for img_file in image_dir.glob(\"*.jpg\"):\n",
        "\n",
        "        # 1. Determine the corresponding label file name (.txt)\n",
        "        label_file = label_dir / (img_file.stem + \".txt\")\n",
        "\n",
        "        # 2. Check and process label file\n",
        "        if not label_file.exists():\n",
        "            # print(f\"Warning: Missing label file for {img_file.name}\") # Too verbose\n",
        "            continue\n",
        "\n",
        "        try:\n",
        "            # Read all lines from the label file\n",
        "            with open(label_file, 'r') as f:\n",
        "                lines = f.readlines()\n",
        "\n",
        "            if not lines:\n",
        "                continue # Skip if label file is empty\n",
        "\n",
        "            # Extract all class IDs (the first number in each row)\n",
        "            class_ids = [int(line.strip().split()[0]) for line in lines]\n",
        "\n",
        "            # Find the majority class ID (the most frequent insect)\n",
        "            # bincount is efficient for finding frequencies of non-negative integers\n",
        "            class_counts = np.bincount(class_ids)\n",
        "            majority_class_id = np.argmax(class_counts)\n",
        "\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading label {label_file.name}: {e}\")\n",
        "            continue\n",
        "\n",
        "        # 3. Load and Preprocess Image\n",
        "        # Load as color image (3 channels) for consistent feature count\n",
        "        img = cv2.imread(str(img_file), cv2.IMREAD_COLOR)\n",
        "\n",
        "        if img is not None:\n",
        "            # Resize, flatten, and normalize\n",
        "            img = cv2.resize(img, (img_size, img_size))\n",
        "            img_normalized = img.astype('float32') / 255.0\n",
        "\n",
        "            X_list.append(img_normalized.flatten())\n",
        "            y_list.append(majority_class_id) # Use the derived majority class\n",
        "\n",
        "    # 4. Final array creation (handles the 2D shape requirement)\n",
        "    X = np.array(X_list, dtype='float32')\n",
        "    y = np.array(y_list)\n",
        "\n",
        "    print(f\"Loaded {len(X)} samples for {split_name}. Final shape: {X.shape}\")\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "l8zo0YMDkvr5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noise and Filter Analysis"
      ],
      "metadata": {
        "id": "fjEM2WtaaQT_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_corruption_to_folder(source_dir, destination_dir, corruption_type, strength=0.01):\n",
        "    \"\"\"\n",
        "    Copies images from source to destination and applies a specified corruption.\n",
        "    (Function body is omitted here for brevity, assuming the user's provided code is used)\n",
        "    \"\"\"\n",
        "    if destination_dir.exists():\n",
        "        shutil.rmtree(destination_dir)\n",
        "    shutil.copytree(source_dir, destination_dir)\n",
        "\n",
        "    if corruption_type == 'gaussian_noise':\n",
        "        sigma = int(strength * 255)\n",
        "        print(f\"\\nApplying {corruption_type} (Sigma: {sigma}) to images in {destination_dir.name}...\")\n",
        "        for img_file in destination_dir.glob('*.jpg'):\n",
        "            img = cv2.imread(str(img_file))\n",
        "            if img is None: continue\n",
        "            noise = np.random.normal(0, sigma, img.shape).astype('uint8')\n",
        "            corrupted_img = cv2.add(img, noise)\n",
        "            cv2.imwrite(str(img_file), corrupted_img)\n",
        "\n",
        "    elif corruption_type == 'salt_pepper_noise':\n",
        "        ratio = strength\n",
        "        print(f\"\\nApplying {corruption_type} (Ratio: {ratio}) to images in {destination_dir.name}...\")\n",
        "        for img_file in destination_dir.glob('*.jpg'):\n",
        "            img = cv2.imread(str(img_file))\n",
        "            if img is None: continue\n",
        "            corrupted_img = img.copy()\n",
        "            total_pixels = img.size\n",
        "\n",
        "            # TODO: verify the logic of this part, it seems the img coords is always pepper (0)\n",
        "            # num_salt_pepper = int(ratio * total_pixels / img.shape[2])\n",
        "            # coords = [np.random.randint(0, i - 1, num_salt_pepper) for i in img.shape]\n",
        "            # corrupted_img[coords[0], coords[1], coords[2]] = 255\n",
        "            # coords = [np.random.randint(0, i - 1, num_salt_pepper) for i in img.shape]\n",
        "            # corrupted_img[coords[0], coords[1], coords[2]] = 0\n",
        "            # cv2.imwrite(str(img_file), corrupted_img)\n",
        "\n",
        "\n",
        "            num_corrupt_elements = int(ratio * total_pixels)\n",
        "            flat_indices = np.random.choice(\n",
        "                total_pixels,\n",
        "                size=num_corrupt_elements,\n",
        "                replace=False\n",
        "            )\n",
        "            num_salt = num_pepper = num_corrupt_elements // 2\n",
        "\n",
        "            # Apply Salt (White)\n",
        "            salt_indices = flat_indices[:num_salt]\n",
        "            corrupted_img.flat[salt_indices] = 255\n",
        "\n",
        "            # Apply Pepper (Black)\n",
        "            pepper_indices = flat_indices[num_salt:num_salt + num_pepper]\n",
        "            corrupted_img.flat[pepper_indices] = 0\n",
        "\n",
        "    elif corruption_type == 'gaussian_blur':\n",
        "        ksize = int(strength * 100) if int(strength * 100) % 2 != 0 else int(strength * 100) + 1\n",
        "        print(f\"\\nApplying {corruption_type} (ksize: {ksize}) to images in {destination_dir.name}...\")\n",
        "        for img_file in destination_dir.glob('*.jpg'):\n",
        "            img = cv2.imread(str(img_file))\n",
        "            if img is None: continue\n",
        "            corrupted_img = cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
        "            cv2.imwrite(str(img_file), corrupted_img)\n",
        "\n",
        "    print(\"Corruption application complete.\")\n",
        "\n",
        "\n",
        "VAL_DIR_NAME = \"valid\"\n",
        "if APPLY_CORRUPTION:\n",
        "    original_val_path = local_path / VAL_DIR_NAME\n",
        "    corrupt_val_path_name = f\"{VAL_DIR_NAME}_corrupted\"\n",
        "    corrupt_val_path = local_path / corrupt_val_path_name\n",
        "\n",
        "    # Create the corrupted validation set by copying and modifying the 'valid' split\n",
        "    apply_corruption_to_folder(\n",
        "        original_val_path,\n",
        "        corrupt_val_path,\n",
        "        CORRUPT_TYPE,\n",
        "        CORRUPT_STRENGTH\n",
        "    )\n",
        "    VAL_DIR_NAME = corrupt_val_path_name # Switch the validation directory name"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-QCrLSKbaSqU",
        "outputId": "7da66e4e-e3c0-4cb4-fd02-b7442343922b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Applying gaussian_blur (ksize: 5) to images in valid_corrupted...\n",
            "Corruption application complete.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load Data Splits"
      ],
      "metadata": {
        "id": "LiJYeVN0aW1e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 4. Load Data Splits ---\n",
        "X_train, y_train = load_split_data(local_path, \"train\", CLASS_MAP, RESOLUTION)\n",
        "\n",
        "# Load validation data (clean or corrupted)\n",
        "X_val, y_val = load_split_data(local_path, VAL_DIR_NAME, CLASS_MAP, RESOLUTION)\n",
        "\n",
        "# Load test data\n",
        "X_test, y_test = load_split_data(local_path, \"test\", CLASS_MAP, RESOLUTION)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9H1ZJQY9aYKs",
        "outputId": "d18c976e-26c4-4b51-c54e-721992a35f04"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Processing images in: /content/datasets/crop-pests/train/images\n",
            "Loaded 11499 samples for train. Final shape: (11499, 12288)\n",
            "\n",
            "Processing images in: /content/datasets/crop-pests/valid_corrupted/images\n",
            "Loaded 1095 samples for valid_corrupted. Final shape: (1095, 12288)\n",
            "\n",
            "Processing images in: /content/datasets/crop-pests/test/images\n",
            "Loaded 546 samples for test. Final shape: (546, 12288)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# format time for metrics in next stage\n",
        "def format_time(seconds):\n",
        "    \"\"\"Converts total seconds into minutes and seconds format.\"\"\"\n",
        "    # Ensure all time variables (train_time, val_time, test_time) are available\n",
        "    mins, secs = divmod(seconds, 60)\n",
        "    return f\"{int(mins):0d}m {secs:.2f}s\""
      ],
      "metadata": {
        "id": "KeJd7_PM_WuB"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### KNN Classifier — Train model, prediction and evaluation"
      ],
      "metadata": {
        "id": "C6OKAJK2acIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Model\n",
        "knn_classifier = KNeighborsClassifier(n_neighbors=K_NEIGHBORS)\n",
        "\n",
        "start = time.time()\n",
        "knn_classifier.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "knn_train_time = end - start\n",
        "\n",
        "start_kernel = time.time()\n",
        "knn_val_pred = knn_classifier.predict(X_val)\n",
        "end = time.time()\n",
        "knn_val_time = end - start\n",
        "\n",
        "knn_val_probas = knn_classifier.predict_proba(X_val)\n",
        "\n",
        "start = time.time()\n",
        "knn_test_pred = knn_classifier.predict(X_test)\n",
        "end = time.time()\n",
        "knn_test_time = end - start\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 418
        },
        "id": "_PPB92IEailE",
        "outputId": "ff1e6ad5-433f-4961-f5c8-cc96e044516e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-853628067.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mstart_kernel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mknn_val_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mknn_val_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    260\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             ):\n\u001b[0;32m--> 262\u001b[0;31m                 \u001b[0mprobabilities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    263\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs_2d_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m                     return np.stack(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/neighbors/_classification.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0;31m# In that case, we do not need the distances to perform\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m             \u001b[0;31m# the weighting so we do not compute them.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 371\u001b[0;31m             \u001b[0mneigh_ind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_distance\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m             \u001b[0mneigh_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/neighbors/_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[0;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[1;32m    867\u001b[0m         )\n\u001b[1;32m    868\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muse_pairwise_distances_reductions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 869\u001b[0;31m             results = ArgKmin.compute(\n\u001b[0m\u001b[1;32m    870\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_X\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/sklearn/metrics/_pairwise_distances_reduction/_dispatcher.py\u001b[0m in \u001b[0;36mcompute\u001b[0;34m(cls, X, Y, k, metric, chunk_size, metric_kwargs, strategy, return_distance)\u001b[0m\n\u001b[1;32m    291\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             return ArgKmin32.compute(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mY\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32msklearn/metrics/_pairwise_distances_reduction/_argkmin.pyx\u001b[0m in \u001b[0;36msklearn.metrics._pairwise_distances_reduction._argkmin.ArgKmin32.compute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/threadpoolctl.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    593\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestore_original_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics\n",
        "# We use the 'weighted' average suitable for multi-class, potentially imbalanced data.\n",
        "accuracy = metrics.accuracy_score(y_val, knn_val_pred)\n",
        "precision, recall, f1_score, _ = metrics.precision_recall_fscore_support(\n",
        "    y_val, knn_val_pred, average='weighted', zero_division=0\n",
        ")\n",
        "\n",
        "# AUC is calculated in a One-vs-Rest fashion for multi-class problems.\n",
        "# The true labels (y_val) must be binarized first.\n",
        "lb = LabelBinarizer()\n",
        "y_val_binarized = lb.fit_transform(y_val)\n",
        "\n",
        "# We use the 'weighted' average to account for class support\n",
        "auc_score = metrics.roc_auc_score(\n",
        "    y_val_binarized,\n",
        "    knn_val_probas,\n",
        "    average='weighted',\n",
        "    multi_class='ovr'\n",
        ")\n",
        "\n",
        "# --- 4. Output Refactored Metrics ---\n",
        "print(f\"Results for KNN (K={K_NEIGHBORS}) with image size {RESOLUTION} and {f\"{CORRUPT_TYPE}, strength set to {CORRUPT_STRENGTH}\" if APPLY_CORRUPTION else \"no filters\"}:\\n\")\n",
        "\n",
        "# NOTE: mAP is not available for KNN (Classification)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision (Weighted): {precision:.4f}\")\n",
        "print(f\"Recall (Weighted): {recall:.4f}\")\n",
        "print(f\"F1-Score (Weighted): {f1_score:.4f}\")\n",
        "print(f\"Area Under the Curve (AUC): {auc_score:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining Time (Total): {format_time(knn_train_time)}\")\n",
        "print(f\"Validation Time (Prediction): {format_time(knn_val_time)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XU32-Ylor7Lr",
        "outputId": "50214196-38aa-4d6f-a89e-95f85efa8fdd"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for KNN (K=5) with image size 64 and gaussian_blur, strength set to 0.05:\n",
            "\n",
            "Accuracy: 0.1653\n",
            "Precision (Weighted): 0.1874\n",
            "Recall (Weighted): 0.1653\n",
            "F1-Score (Weighted): 0.1505\n",
            "Area Under the Curve (AUC): 0.5918\n",
            "\n",
            "Training Time (Total): 0m 0.08s\n",
            "Validation Time (Prediction): 0m 15.34s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Decision Tree Classifier — Train model, prediction and evaluation"
      ],
      "metadata": {
        "id": "SgoAVtCs1Vqr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dt_classifier = DecisionTreeClassifier()\n",
        "\n",
        "start = time.time()\n",
        "dt_classifier.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "dt_train_time = end - start\n",
        "\n",
        "start_kernel = time.time()\n",
        "dt_val_pred = dt_classifier.predict(X_val)\n",
        "end = time.time()\n",
        "dt_val_time = end - start\n",
        "\n",
        "dt_val_probas = dt_classifier.predict_proba(X_val)\n",
        "\n",
        "start = time.time()\n",
        "dt_test_pred = dt_classifier.predict(X_test)\n",
        "end = time.time()\n",
        "dt_test_time = end - start"
      ],
      "metadata": {
        "id": "_7Cfov6a1XYe"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics\n",
        "# We use the 'weighted' average suitable for multi-class, potentially imbalanced data.\n",
        "accuracy = metrics.accuracy_score(y_val, dt_val_pred)\n",
        "precision, recall, f1_score, _ = metrics.precision_recall_fscore_support(\n",
        "    y_val, dt_val_pred, average='weighted', zero_division=0\n",
        ")\n",
        "\n",
        "# AUC is calculated in a One-vs-Rest fashion for multi-class problems.\n",
        "# The true labels (y_val) must be binarized first.\n",
        "lb = LabelBinarizer()\n",
        "y_val_binarized = lb.fit_transform(y_val)\n",
        "\n",
        "# We use the 'weighted' average to account for class support\n",
        "auc_score = metrics.roc_auc_score(\n",
        "    y_val_binarized,\n",
        "    dt_val_probas,\n",
        "    average='weighted',\n",
        "    multi_class='ovr'\n",
        ")\n",
        "\n",
        "\n",
        "# --- 4. Output Refactored Metrics ---\n",
        "print(f\"Results for DT with image size {RESOLUTION} and {f\"{CORRUPT_TYPE}, strength set to {CORRUPT_STRENGTH}\" if APPLY_CORRUPTION else \"no filters\"}:\\n\")\n",
        "\n",
        "# NOTE: mAP is not available for KNN (Classification)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision (Weighted): {precision:.4f}\")\n",
        "print(f\"Recall (Weighted): {recall:.4f}\")\n",
        "print(f\"F1-Score (Weighted): {f1_score:.4f}\")\n",
        "print(f\"Area Under the Curve (AUC): {auc_score:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining Time (Total): {format_time(dt_train_time)}\")\n",
        "print(f\"Validation Time (Prediction): {format_time(dt_val_time)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lNoj_NrD1XqA",
        "outputId": "6bb7796f-eeae-43ba-d5b7-068ea84d562e"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for DT with image size 64 and gaussian_blur, strength set to 0.05:\n",
            "\n",
            "Accuracy: 0.1251\n",
            "Precision (Weighted): 0.1253\n",
            "Recall (Weighted): 0.1251\n",
            "F1-Score (Weighted): 0.1246\n",
            "Area Under the Curve (AUC): 0.5222\n",
            "\n",
            "Training Time (Total): 4m 49.06s\n",
            "Validation Time (Prediction): 4m 49.08s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### SGD Classifier — Train model, prediction and evaluation"
      ],
      "metadata": {
        "id": "p3w6utSW1ZUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sgd_classifier = SGDClassifier(loss='log_loss', max_iter=250, random_state=42)\n",
        "\n",
        "start = time.time()\n",
        "sgd_classifier.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "sgd_train_time = end - start\n",
        "\n",
        "start = time.time()\n",
        "sgd_val_pred = sgd_classifier.predict(X_val)\n",
        "end = time.time()\n",
        "sgd_val_time = end - start\n",
        "\n",
        "sgd_val_probas = sgd_classifier.predict_proba(X_val)\n",
        "\n",
        "start = time.time()\n",
        "sgd_test_pred = sgd_classifier.predict(X_test)\n",
        "end = time.time()\n",
        "sgd_test_time = end - start"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qnKFjyFj1cc4",
        "outputId": "67522027-c23a-4726-a3a8-493d46a1699f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/sklearn/linear_model/_stochastic_gradient.py:738: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluation metrics\n",
        "# We use the 'weighted' average suitable for multi-class, potentially imbalanced data.\n",
        "accuracy = metrics.accuracy_score(y_val, sgd_val_pred)\n",
        "precision, recall, f1_score, _ = metrics.precision_recall_fscore_support(\n",
        "    y_val, sgd_val_pred, average='weighted', zero_division=0\n",
        ")\n",
        "\n",
        "# AUC is calculated in a One-vs-Rest fashion for multi-class problems.\n",
        "# The true labels (y_val) must be binarized first.\n",
        "lb = LabelBinarizer()\n",
        "y_val_binarized = lb.fit_transform(y_val)\n",
        "\n",
        "# We use the 'weighted' average to account for class support\n",
        "auc_score = metrics.roc_auc_score(\n",
        "    y_val_binarized,\n",
        "    sgd_val_probas,\n",
        "    average='weighted',\n",
        "    multi_class='ovr'\n",
        ")\n",
        "\n",
        "\n",
        "# --- 4. Output Refactored Metrics ---\n",
        "print(f\"Results for SGD with image size {RESOLUTION} and {f\"{CORRUPT_TYPE}, strength set to {CORRUPT_STRENGTH}\" if APPLY_CORRUPTION else \"no filters\"}:\\n\")\n",
        "\n",
        "# NOTE: mAP is not available for KNN (Classification)\n",
        "print(f\"Accuracy: {accuracy:.4f}\")\n",
        "print(f\"Precision (Weighted): {precision:.4f}\")\n",
        "print(f\"Recall (Weighted): {recall:.4f}\")\n",
        "print(f\"F1-Score (Weighted): {f1_score:.4f}\")\n",
        "print(f\"Area Under the Curve (AUC): {auc_score:.4f}\")\n",
        "\n",
        "print(f\"\\nTraining Time (Total): {format_time(sgd_train_time)}\")\n",
        "print(f\"Validation Time (Prediction): {format_time(sgd_val_time)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZhRmHvl1crl",
        "outputId": "3f9cadd2-5dd5-4b39-c787-f77eb5065974"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results for SGD with image size 64 and gaussian_blur, strength set to 0.05:\n",
            "\n",
            "Accuracy: 0.1443\n",
            "Precision (Weighted): 0.1828\n",
            "Recall (Weighted): 0.1443\n",
            "F1-Score (Weighted): 0.1412\n",
            "Area Under the Curve (AUC): 0.6065\n",
            "\n",
            "Training Time (Total): 14m 16.49s\n",
            "Validation Time (Prediction): 0m 0.03s\n"
          ]
        }
      ]
    }
  ]
}