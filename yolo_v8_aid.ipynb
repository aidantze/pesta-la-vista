{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyORj+4Jjv53h3g3jl6N1yD4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aidantze/pesta-la-vista/blob/yolo_v8/yolo_v8_aid.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Yolo v8"
      ],
      "metadata": {
        "id": "1VOqp0_A0OaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup"
      ],
      "metadata": {
        "id": "3Yt9hHP10TS1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "-w-ocdOwJhpM",
        "outputId": "c0c63f50-dd27-449a-d24b-56ef07612ea0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCreating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "CUDA available: True\n",
            "GPU: Tesla T4\n",
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/rupankarmajumdar/crop-pests-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 537M/537M [00:02<00:00, 215MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics kagglehub pyyaml\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import kagglehub\n",
        "import pathlib\n",
        "import yaml\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "import torch\n",
        "import time\n",
        "\n",
        "# Check for T4 availability on Colab (DON'T CHANGE)\n",
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU detected. Go to Runtime -> Change runtime type ->  GPU\")\n",
        "\n",
        "# Kaggle Download via CLI API (see their website - DON'T CHANGE)\n",
        "path = kagglehub.dataset_download(\"rupankarmajumdar/crop-pests-dataset\")\n",
        "\n",
        "# Saved the images to a local path to increase efficiency\n",
        "local_path = pathlib.Path(\"/content/datasets/crop-pests\")\n",
        "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "shutil.copytree(path, local_path, dirs_exist_ok=True)\n",
        "\n",
        "# YAML CONGIF (DON'T CHANGE)\n",
        "data_yaml_path = local_path / \"data.yaml\"\n",
        "data_cfg = {\n",
        "    \"path\": str(local_path),\n",
        "    \"train\": \"train/images\",\n",
        "    \"val\":   \"valid/images\",\n",
        "    \"test\":  \"test/images\",\n",
        "    \"names\": [\n",
        "        \"ant\", \"bee\", \"beetle\", \"caterpillar\", \"earthworm\", \"earwig\",\n",
        "        \"grasshopper\", \"moth\", \"slug\", \"snail\", \"wasp\", \"weevil\"\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    yaml.safe_dump(data_cfg, f)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Noise and Filter/Blur Analysis"
      ],
      "metadata": {
        "id": "MCCHT7HH0-E2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Noise and filter/blur analysis\n",
        "def apply_corruption_to_folder(source_dir, destination_dir, corruption_type, strength=0.01):\n",
        "    \"\"\"\n",
        "    Copies images from source to destination and applies a specified corruption.\n",
        "\n",
        "    Args:\n",
        "        source_dir (pathlib.Path): Directory containing original images.\n",
        "        destination_dir (pathlib.Path): Target directory for corrupted images.\n",
        "        corruption_type (str): 'gaussian_noise', 'salt_pepper_noise', 'gaussian_blur'.\n",
        "        strength (float/int): Magnitude of the corruption.\n",
        "    \"\"\"\n",
        "    if destination_dir.exists():\n",
        "        shutil.rmtree(destination_dir)\n",
        "    shutil.copytree(source_dir, destination_dir)\n",
        "\n",
        "    print(f\"\\nApplying {corruption_type} (Strength: {strength}) to images in {destination_dir.name}...\")\n",
        "\n",
        "    for img_file in destination_dir.glob('*.jpg'): # Adjust extension if needed\n",
        "        img = cv2.imread(str(img_file))\n",
        "        if img is None:\n",
        "            continue\n",
        "\n",
        "        if corruption_type == 'gaussian_noise':\n",
        "            # Mean=0, standard deviation=strength * 255\n",
        "            sigma = int(strength * 255)\n",
        "            noise = np.random.normal(0, sigma, img.shape).astype('uint8')\n",
        "            corrupted_img = cv2.add(img, noise)\n",
        "\n",
        "        elif corruption_type == 'salt_pepper_noise':\n",
        "            ratio = strength # Ratio of pixels to corrupt\n",
        "            corrupted_img = img.copy()\n",
        "            total_pixels = img.size\n",
        "            num_salt_pepper = int(ratio * total_pixels / img.shape[2]) # Total pixels / num channels\n",
        "\n",
        "            # Salt noise (white)\n",
        "            coords = [np.random.randint(0, i - 1, num_salt_pepper) for i in img.shape]\n",
        "            corrupted_img[coords[0], coords[1], coords[2]] = 255\n",
        "\n",
        "            # Pepper noise (black)\n",
        "            coords = [np.random.randint(0, i - 1, num_salt_pepper) for i in img.shape]\n",
        "            corrupted_img[coords[0], coords[1], coords[2]] = 0\n",
        "\n",
        "        elif corruption_type == 'gaussian_blur':\n",
        "            # Kernel size = strength (must be odd), sigma=0 (auto)\n",
        "            ksize = strength if strength % 2 != 0 else strength + 1\n",
        "            corrupted_img = cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
        "\n",
        "        # Save the corrupted image, overwriting the copy\n",
        "        cv2.imwrite(str(img_file), corrupted_img)\n",
        "\n",
        "    print(\"Corruption application complete.\")\n",
        "\n",
        "\n",
        "# --- Integration into your Main Code ---\n",
        "# ... (Your existing code up to YAML CONFIG)\n",
        "\n",
        "# NEW STEP: Set up the corrupted test directory\n",
        "CORRUPT_TYPE = 'gaussian_noise'\n",
        "CORRUPT_STRENGTH = 0.05  # e.g., 5% noise or 5x5 kernel blur\n",
        "\n",
        "# Create a new validation directory for the corrupted test set\n",
        "original_val_path = local_path / \"valid\" / \"images\"\n",
        "corrupt_val_path = local_path / \"valid_noisy\" / \"images\"\n",
        "\n",
        "# Apply corruption to the copied test set\n",
        "# We use 'valid' here since YOLOv8 validation defaults to the 'val' split name.\n",
        "apply_corruption_to_folder(\n",
        "    original_val_path,\n",
        "    corrupt_val_path,\n",
        "    CORRUPT_TYPE,\n",
        "    CORRUPT_STRENGTH\n",
        ")\n",
        "\n",
        "# Update the YAML to point to the corrupted validation set for the experiment\n",
        "data_cfg_corrupted = data_cfg.copy()\n",
        "data_cfg_corrupted['val'] = \"valid_noisy/images\"\n",
        "data_yaml_path_corrupted = local_path / \"data_corrupted.yaml\"\n",
        "\n",
        "with open(data_yaml_path_corrupted, \"w\") as f:\n",
        "    yaml.safe_dump(data_cfg_corrupted, f)\n",
        "print(\"Wrote corrupted config:\", data_yaml_path_corrupted)"
      ],
      "metadata": {
        "id": "kA1KUeVg0Kia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train model and prediction"
      ],
      "metadata": {
        "id": "uro6Ql8Z1Ai3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the Model (as per YOLOv8n website)\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "RESOLUTION = 512\n",
        "\n",
        "# See changes made to increase for Colab\n",
        "start = time.time()\n",
        "train_res = model.train(\n",
        "    data=str(data_yaml_path),\n",
        "    epochs=10,           # set to 10 for testing, leave as 30 default\n",
        "    imgsz=RESOLUTION,\n",
        "    batch=-1,            # auto batch size based on GPU memory\n",
        "    device=0,            # use GPU (CUDA:0)\n",
        "    workers=4,           # increase data loading threads\n",
        "    cache=True,          # cache dataset in RAM/Disk for speed\n",
        "    amp=True,            # mixed precision\n",
        "    freeze=10,           # aka for transfer learning (recommended by AI)\n",
        "    mosaic=0.5,          # light augmentations\n",
        "    mixup=0.0,\n",
        "    copy_paste=0.0,\n",
        "    project=\"pests_fast\",\n",
        "    name=\"yolov8n_colab\",\n",
        "    plots=False\n",
        ")\n",
        "end = time.time()\n",
        "train_time = end - start\n",
        "\n",
        "# Validate the Model (as per YOLOv8n website)\n",
        "start = time.time()\n",
        "val_results = model.val(\n",
        "    data=str(data_yaml_path),\n",
        "    split=\"test\",\n",
        "    batch=16,\n",
        "    device=0,\n",
        "    workers=2\n",
        ")\n",
        "end = time.time()\n",
        "val_time = end - start\n",
        "print(val_results)\n",
        "\n",
        "# Test the Model (as per YOLOv8n website)\n",
        "sample_dir = local_path / \"test\" / \"images\"\n",
        "start = time.time()\n",
        "test_results = model.predict(\n",
        "    source=str(sample_dir),\n",
        "    batch=16,\n",
        "    imgsz=RESOLUTION,\n",
        "    device=0,\n",
        "    save=True,\n",
        "    project=\"runs/detect\",\n",
        "    name=\"pest_predictions\"\n",
        ")\n",
        "end = time.time()\n",
        "test_time = end - start"
      ],
      "metadata": {
        "id": "6BqpsDnu0KT1",
        "outputId": "6b086e33-39c5-4f46-c29c-0060939c89e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'YOLO' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-548301611.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Training the Model (as per YOLOv8n website)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mYOLO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"yolov8n.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mRESOLUTION\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'YOLO' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Output Metrics"
      ],
      "metadata": {
        "id": "yyEZLxUzLD6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Mean Average Precision (mAP)\n",
        "mAP50 = val_results.results_dict['metrics/mAP50(B)']\n",
        "mAP50_95 = val_results.results_dict['metrics/mAP50-95(B)']\n",
        "\n",
        "# Precision, Recall, and F1-score\n",
        "precision = val_results.results_dict['metrics/precision(B)']\n",
        "recall = val_results.results_dict['metrics/recall(B)']\n",
        "f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
        "\n",
        "# Note: YOLO does not directly output a single 'Accuracy' metric in the classification sense,\n",
        "# nor a single 'Area Under the Curve (AUC)' value; mAP is the primary AUC equivalent.\n",
        "\n",
        "print(f\"Mean Average Precision (mAP@0.50): {mAP50:.4f}\")\n",
        "print(f\"Mean Average Precision (mAP@0.50-0.95): {mAP50_95:.4f}\")\n",
        "print(f\"Precision (Box): {precision:.4f}\")\n",
        "print(f\"Recall (Box): {recall:.4f}\")\n",
        "print(f\"F1-Score (Derived): {f1_score:.4f}\\n\")\n",
        "\n",
        "def format_time(seconds):\n",
        "    \"\"\"Converts total seconds into minutes and format.\"\"\"\n",
        "    mins, secs = divmod(seconds, 60)\n",
        "    return f\"{int(mins):0d}m {secs:.2f}s\"\n",
        "\n",
        "print(f\"Training Time (Total): {format_time(train_time)}\")\n",
        "print(f\"Testing/Validation Time (Total): {format_time(test_time)}\")"
      ],
      "metadata": {
        "id": "vT5Z2W_LLAX4",
        "outputId": "1143b2ae-94e9-46f9-89d3-ac51d54575bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Average Precision (mAP@0.50): 0.6974\n",
            "Mean Average Precision (mAP@0.50-0.95): 0.4086\n",
            "Precision (Box): 0.7537\n",
            "Recall (Box): 0.6391\n",
            "F1-Score (Derived): 0.6917\n",
            "\n",
            "Training Time (Total): 22m 38.38s\n",
            "Testing/Validation Time (Total): 2m 14.29s\n"
          ]
        }
      ]
    }
  ]
}