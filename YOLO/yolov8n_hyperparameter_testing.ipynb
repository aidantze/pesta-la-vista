{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u2S6KJeTNMj"
      },
      "source": [
        "# **Starter Code**\n",
        "- Imports\n",
        "- Checking GPU availability\n",
        "- Getting the Kaggle set and description of the download\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_oCJdJUR9fe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install -q ultralytics kagglehub pyyaml opencv-python efficientnet_pytorch torch torchvision\n",
        "import torch\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "import pathlib\n",
        "import yaml\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import random\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4B_5ChgSSNj"
      },
      "outputs": [],
      "source": [
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():     # Check for T4 availability on Colab (DON'T CHANGE)\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU detected. Go to Runtime -> Change runtime type ->  GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1bGCMx-SXD8"
      },
      "outputs": [],
      "source": [
        "\n",
        "path = kagglehub.dataset_download(\"rupankarmajumdar/crop-pests-dataset\")      # Getting the DATASET from kagglehub via CLI API (see their website - DON'T CHANGE)\n",
        "\n",
        "local_path = pathlib.Path(\"/content/datasets/crop-pests\")     # Saved the images to a local path to increase efficiency\n",
        "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "shutil.copytree(path, local_path, dirs_exist_ok=True)\n",
        "\n",
        "data_yaml_path = local_path / \"data.yaml\"     # YAML CONGIF (DON'T CHANGE)\n",
        "data_cfg = {\n",
        "    \"path\": str(local_path),\n",
        "    \"train\": \"train/images\",\n",
        "    \"val\":   \"valid/images\",\n",
        "    \"test\":  \"test/images\",\n",
        "    \"nc\": 12,\n",
        "    \"names\":\n",
        "     [\n",
        "      \"Ants\",\n",
        "      \"Bees\",\n",
        "      \"Beetles\",\n",
        "      \"Catterpillars\",     # NOTE: HAD TO CHANGE SPELLING BECAUSE DATASET IMAGES ARE SPELT LIKE THIS\n",
        "      \"Earthworms\",\n",
        "      \"Earwigs\",\n",
        "      \"Grasshoppers\",\n",
        "      \"Moths\",\n",
        "      \"Slugs\",\n",
        "      \"Snails\",\n",
        "      \"Wasps\",\n",
        "      \"Weevils\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    yaml.safe_dump(data_cfg, f)\n",
        "\n",
        "\n",
        "# CHECKS\n",
        "num_train_images = len(list((local_path / \"train\" / \"images\").glob(\"*.jpg\")))\n",
        "num_val_images = len(list((local_path / \"valid\" / \"images\").glob(\"*.jpg\")))\n",
        "num_test_images = len(list((local_path / \"test\" / \"images\").glob(\"*.jpg\")))\n",
        "\n",
        "num_train_labels = len(list((local_path / \"train\" / \"labels\").glob(\"*.txt\")))\n",
        "num_val_labels = len(list((local_path / \"valid\" / \"labels\").glob(\"*.txt\")))\n",
        "num_test_labels = len(list((local_path / \"test\" / \"labels\").glob(\"*.txt\")))\n",
        "\n",
        "print(f\"Number of training images: {num_train_images}\")\n",
        "print(f\"Number of validation images: {num_val_images}\")\n",
        "print(f\"Number of test images: {num_test_images}\")\n",
        "print(f\"Number of training labels: {num_train_labels}\")\n",
        "print(f\"Number of validation labels: {num_val_labels}\")\n",
        "print(f\"Number of test labels: {num_test_labels}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkuLvvScTcpn"
      },
      "source": [
        "# **Our Evaluation Metrics**\n",
        "- mAP@0.5 >= 0.5\n",
        "- mAP@0.5:0.95 (elps you detect over/under-sized bounding boxes)\n",
        "- Precision (false positive control)\n",
        "- Recall (false negative control)\n",
        "- F1 score\n",
        "- Training and Testing times\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0w3De9jVddK"
      },
      "outputs": [],
      "source": [
        "def base_evaluation_metrics(val_results):\n",
        "    metrics = val_results.results_dict\n",
        "    precision = metrics.get('metrics/precision(B)', 0)\n",
        "    recall    = metrics.get('metrics/recall(B)', 0)\n",
        "    mAP50     = metrics.get('metrics/mAP50(B)', 0)\n",
        "    mAP50_95  = metrics.get('metrics/mAP50-95(B)', 0)\n",
        "    f1_score  = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
        "    print(f\"\\nMean Average Precision (mAP@0.5):        {mAP50:.4f}\")\n",
        "    print(f\"Mean Average Precision (mAP@0.5:0.95):   {mAP50_95:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}  |  Recall: {recall:.4f}  |  F1-score: {f1_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9-hASZH932E"
      },
      "outputs": [],
      "source": [
        "def format_time(seconds):\n",
        "    mins, secs = divmod(seconds, 60)      # Converts total seconds into minutes and format.\n",
        "    return f\"{int(mins):0d}m {secs:.2f}s\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2IMcHMXoMWf"
      },
      "source": [
        "# Noise and Filter/Blur CHECK\n",
        "--------------------------------------------------------\n",
        "- Gaussian Noise\n",
        "- Salt & Pepper\n",
        "- Gaussian Blur"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Px03Z1rV9hjk"
      },
      "outputs": [],
      "source": [
        "# Noise and filter constants\n",
        "APPLY_CORRUPTION = True\n",
        "CORRUPT_TYPE = 'gaussian_blur'   # one of: 'gaussian_noise', 'salt_pepper_noise', 'gaussian_blur'\n",
        "CORRUPT_STRENGTH = 0.2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MR8Q68inixBD"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Noise and filter/blur analysis\n",
        "def apply_corruption_to_folder(source_img_dir, destination_img_dir, corruption_type, strength=0.01):\n",
        "    source_lbl_dir = source_img_dir.parent / \"labels\"     # Determine corresponding label directories\n",
        "    destination_lbl_dir = destination_img_dir.parent / \"labels\"\n",
        "\n",
        "    if destination_img_dir.exists():      # Remove existing destination directories if they exist\n",
        "        shutil.rmtree(destination_img_dir)\n",
        "    if destination_lbl_dir.exists():\n",
        "        shutil.rmtree(destination_lbl_dir)\n",
        "\n",
        "    shutil.copytree(source_img_dir, destination_img_dir)       # Copy images and labels\n",
        "    if source_lbl_dir.exists():\n",
        "        shutil.copytree(source_lbl_dir, destination_lbl_dir)\n",
        "\n",
        "\n",
        "    if corruption_type == 'gaussian_noise':\n",
        "        sigma = int(strength * 255)\n",
        "        print(f\"\\nApplying {corruption_type} (Sigma: {sigma}) to images in {destination_img_dir.name}...\")\n",
        "\n",
        "        for img_file in destination_img_dir.glob('*.jpg'):      # Adjust extension if needed\n",
        "            img = cv2.imread(str(img_file))\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            img_f = img.astype(np.float32)\n",
        "            noise = np.random.normal(0, sigma, img.shape).astype(np.float32)\n",
        "            corrupted_img = img_f + noise\n",
        "            corrupted_img = np.clip(corrupted_img, 0, 255).astype(np.uint8)\n",
        "            cv2.imwrite(str(img_file), corrupted_img)\n",
        "\n",
        "    elif corruption_type == 'salt_pepper_noise':\n",
        "        ratio = strength      # Ratio of pixels to corrupt\n",
        "        print(f\"\\nApplying {corruption_type} (Ratio: {ratio}) to images in {destination_img_dir.name}...\")\n",
        "\n",
        "        for img_file in destination_img_dir.glob('*.jpg'):      # Adjust extension if needed\n",
        "            img = cv2.imread(str(img_file))\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            corrupted_img = img.copy()\n",
        "            h, w, c = img.shape\n",
        "            num_pixels = int(ratio * h * w)\n",
        "\n",
        "            # Salt (white)\n",
        "            ys = np.random.randint(0, h, num_pixels)\n",
        "            xs = np.random.randint(0, w, num_pixels)\n",
        "            corrupted_img[ys, xs, :] = 255\n",
        "\n",
        "            # Pepper (black)\n",
        "            ys = np.random.randint(0, h, num_pixels)\n",
        "            xs = np.random.randint(0, w, num_pixels)\n",
        "            corrupted_img[ys, xs, :] = 0\n",
        "\n",
        "            cv2.imwrite(str(img_file), corrupted_img)\n",
        "\n",
        "    elif corruption_type == 'gaussian_blur':\n",
        "        ksize = int(strength * 20)      # scale to 1â€“20\n",
        "        ksize = max(1, ksize)\n",
        "        if ksize % 2 == 0:\n",
        "            ksize += 1\n",
        "\n",
        "        print(f\"\\nApplying {corruption_type} (ksize: {ksize}) to images in {destination_img_dir.name}...\")\n",
        "\n",
        "        for img_file in destination_img_dir.glob('*.jpg'):\n",
        "            img = cv2.imread(str(img_file))\n",
        "            if img is None:\n",
        "                continue\n",
        "\n",
        "            corrupted_img = cv2.GaussianBlur(img, (ksize, ksize), 0)\n",
        "            cv2.imwrite(str(img_file), corrupted_img)\n",
        "\n",
        "\n",
        "if (APPLY_CORRUPTION):\n",
        "  original_val_path = local_path / \"valid\" / \"images\"\n",
        "  corrupt_val_path = local_path / \"valid_noisy\" / \"images\"      # Create a new validation directory for the corrupted test set\n",
        "\n",
        "  apply_corruption_to_folder(\n",
        "      original_val_path,\n",
        "      corrupt_val_path,\n",
        "      CORRUPT_TYPE,\n",
        "      CORRUPT_STRENGTH\n",
        "  )\n",
        "\n",
        "\n",
        "  data_cfg_corrupted = data_cfg.copy()\n",
        "  data_cfg_corrupted['val'] = \"valid_noisy/images\"\n",
        "  data_yaml_path_corrupted = local_path / \"data_corrupted.yaml\"      # Update the YAML to point to the corrupted validation set for the experiment\n",
        "\n",
        "  # CHECK\n",
        "  with open(data_yaml_path_corrupted, \"w\") as f:\n",
        "      yaml.safe_dump(data_cfg_corrupted, f)\n",
        "  print(\"Wrote corrupted config:\", data_yaml_path_corrupted)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_PQLq-LauP2r"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "start = time.time()\n",
        "train_res = model.train(\n",
        "    data=str(data_yaml_path_corrupted if APPLY_CORRUPTION else data_yaml_path),\n",
        "    epochs=10,\n",
        "    imgsz=640,\n",
        "    batch=-1,\n",
        "    device=0,\n",
        "    cache=True,\n",
        "    amp=True,\n",
        "    project=\"pests_fast\",\n",
        "    name=\"yolov8n_colab\",\n",
        "    plots=False\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "train_time = end - start\n",
        "\n",
        "\n",
        "start = time.time()\n",
        "val_results = model.val(\n",
        "    data=str(data_yaml_path_corrupted if APPLY_CORRUPTION else data_yaml_path),     # Ensure this points to the corrupted set if APPLY_CORRUPTION is True\n",
        "    split=\"val\",\n",
        "    batch=16,\n",
        "    iou=0.5,\n",
        "    device=0,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "val_time = end - start\n",
        "\n",
        "\n",
        "base_evaluation_metrics(val_results)\n",
        "print(f\"Training Time (Total): {format_time(train_time)}\")\n",
        "print(f\"Testing/Validation Time (Total): {format_time(val_time)}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cvoJ-MBo9pQf"
      },
      "source": [
        "# Resolution and Mosaic testing\n",
        "\n",
        "------------------------------------------\n",
        "\n",
        "- image_size_list = [64, 128, 256, 512, 640]\n",
        "- mosaic_list = [ 0.2, 0.4, 0.6, 0.8]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rTPgjxtX_qC2"
      },
      "outputs": [],
      "source": [
        "# Load the hypertuned YOLOv8n model\n",
        "\n",
        "def call_model_1(epoch_size=10, image_size=640, mosaic_amount=1.0):\n",
        "  model= YOLO(\"yolov8n.pt\")\n",
        "  start = time.time()\n",
        "  train_res = model.train(\n",
        "      data=str(data_yaml_path),\n",
        "      batch=-1,\n",
        "      device=0,\n",
        "      amp=True,\n",
        "\n",
        "      epochs=epoch_size,\n",
        "      imgsz=image_size,\n",
        "      mosaic=mosaic_amount,\n",
        "      cache=True,\n",
        "\n",
        "\n",
        "      project=\"pests_fast\",\n",
        "      name=\"yolov8n_wiou_like\",\n",
        "  )\n",
        "\n",
        "\n",
        "  end = time.time()\n",
        "  train_time = end - start\n",
        "\n",
        "  start = time.time()\n",
        "  val_results = model.val(\n",
        "      data=str(data_yaml_path),\n",
        "      split=\"val\",\n",
        "      batch=16,\n",
        "      device=0,\n",
        "      iou = 0.5,\n",
        "      workers=2\n",
        "  )\n",
        "\n",
        "  end = time.time()\n",
        "  val_time = end - start\n",
        "\n",
        "  base_evaluation_metrics(val_results)\n",
        "  print(f\"Training Time (Total): {format_time(train_time)}\")\n",
        "  print(f\"Testing/Validation Time (Total): {format_time(val_time)}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HjGmvn8alf_K"
      },
      "outputs": [],
      "source": [
        "image_size_list = [64, 128, 256, 512, 640]\n",
        "\n",
        "# DUE TO RAM ISSUES, CALLED SEPARATELY.\n",
        "# Running on contsant 10 epochs for time\n",
        "\n",
        "# call_model_1(image_size=image_size_list[0])\n",
        "# call_model_1(image_size=image_size_list[1])\n",
        "# call_model_1(image_size=image_size_list[2])\n",
        "# call_model_1(image_size=image_size_list[3])\n",
        "call_model_1(image_size=image_size_list[4])\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1c3dZf0u-_T"
      },
      "source": [
        "**call_model_1(image_size=image_size_list[0])**\n",
        "- Mean Average Precision (mAP@0.5):        0.5145\n",
        "Mean Average Precision (mAP@0.5:0.95):   0.2505\n",
        "Precision: 0.5544  |  Recall: 0.4849  |  F1-score: 0.5173\n",
        "Training Time (Total): 9m 34.87s\n",
        "Testing/Validation Time (Total): 0m 8.76s\n",
        "\n",
        "**call_model_1(image_size=image_size_list[1])**\n",
        "Mean Average Precision (mAP@0.5):        0.6577\n",
        "Mean Average Precision (mAP@0.5:0.95):   0.3768\n",
        "Precision: 0.7324  |  Recall: 0.5873  |  F1-score: 0.6519\n",
        "Training Time (Total): 9m 53.36s\n",
        "Testing/Validation Time (Total): 0m 9.02s\n",
        "\n",
        "**call_model_1(image_size=image_size_list[2])**\n",
        "Mean Average Precision (mAP@0.5):        0.7382\n",
        "Mean Average Precision (mAP@0.5:0.95):   0.4342\n",
        "Precision: 0.8095  |  Recall: 0.6682  |  F1-score: 0.7321\n",
        "Training Time (Total): 9m 51.80s\n",
        "Testing/Validation Time (Total): 0m 9.22s\n",
        "\n",
        "**call_model_1(image_size=image_size_list[3])**\n",
        "Mean Average Precision (mAP@0.5):        0.7359\n",
        "Mean Average Precision (mAP@0.5:0.95):   0.4249\n",
        "Precision: 0.8050  |  Recall: 0.6800  |  F1-score: 0.7372\n",
        "Training Time (Total): 5m 9.23s\n",
        "Testing/Validation Time (Total): 0m 9.47s\n",
        "\n",
        "**call_model_1(image_size=image_size_list[4])**\n",
        "Mean Average Precision (mAP@0.5):        0.7248\n",
        "Mean Average Precision (mAP@0.5:0.95):   0.4099\n",
        "Precision: 0.7818  |  Recall: 0.6710  |  F1-score: 0.7222\n",
        "Training Time (Total): 6m 43.25s\n",
        "Testing/Validation Time (Total): 0m 10.78s"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Smf8InJOqka9"
      },
      "outputs": [],
      "source": [
        "mosaic_list = [0.2, 0.4, 0.6, 0.8]\n",
        "\n",
        "# DUE TO RAM ISSUES, CALLED SEPARATELY.\n",
        "# Running on contsant 10  epochs for time\n",
        "\n",
        "# call_model_1(mosaic_amount=mosaic_list[0])\n",
        "# call_model_1(mosaic_amount=mosaic_list[1])\n",
        "# call_model_1(mosaic_amount=mosaic_list[2])\n",
        "call_model_1(mosaic_amount=mosaic_list[3])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yyembfGuAC0m"
      },
      "source": [
        "**call_model_1(mosaic_amount=mosaic_list[0])**\n",
        "Mean Average Precision (mAP@0.5):        0.7339\n",
        "Mean Average Precision (mAP@0.5:0.95):   0.4147\n",
        "Precision: 0.8058  |  Recall: 0.6660  |  F1-score: 0.7293\n",
        "Training Time (Total): 6m 35.93s\n",
        "Testing/Validation Time (Total): 0m 10.92s\n",
        "\n",
        "**call_model_1(mosaic_amount=mosaic_list[1])**\n",
        "Mean Average Precision (mAP@0.5):        0.7248\n",
        "Mean Average Precision (mAP@0.5:0.95):   0.4099\n",
        "Precision: 0.7818  |  Recall: 0.6710  |  F1-score: 0.7222\n",
        "Training Time (Total): 6m 35.80s\n",
        "Testing/Validation Time (Total): 0m 11.17s\n",
        "\n",
        "**call_model_1(mosaic_amount=mosaic_list[2])**\n",
        "Mean Average Precision (mAP@0.5):        0.7339\n",
        "Mean Average Precision (mAP@0.5:0.95):   0.4147\n",
        "Precision: 0.8058  |  Recall: 0.6660  |  F1-score: 0.7293\n",
        "Training Time (Total): 6m 34.23s\n",
        "Testing/Validation Time (Total): 0m 10.76s\n",
        "\n",
        "**call_model_1(mosaic_amount=mosaic_list[3])**\n",
        "Mean Average Precision (mAP@0.5):        0.7248\n",
        "Mean Average Precision (mAP@0.5:0.95):   0.4099\n",
        "Precision: 0.7818  |  Recall: 0.6710  |  F1-score: 0.7222\n",
        "Training Time (Total): 6m 35.59s\n",
        "Testing/Validation Time (Total): 0m 11.05s\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
