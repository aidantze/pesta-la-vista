{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2u2S6KJeTNMj"
      },
      "source": [
        "# **Starter Code**\n",
        "- Imports\n",
        "- Checking GPU availability\n",
        "- Getting the Kaggle set and description of the download\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L_oCJdJUR9fe"
      },
      "outputs": [],
      "source": [
        "\n",
        "# !pip install -q ultralytics kagglehub pyyaml opencv-python efficientnet_pytorch torch torchvision\n",
        "import torch\n",
        "import numpy as np\n",
        "import kagglehub\n",
        "import pathlib\n",
        "import yaml\n",
        "import shutil\n",
        "from ultralytics import YOLO\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "import random\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4B_5ChgSSNj"
      },
      "outputs": [],
      "source": [
        "print(\"CUDA available:\", torch.cuda.is_available())\n",
        "if torch.cuda.is_available():     # Check for T4 availability on Colab (DON'T CHANGE)\n",
        "    print(\"GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU detected. Go to Runtime -> Change runtime type ->  GPU\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z1bGCMx-SXD8"
      },
      "outputs": [],
      "source": [
        "\n",
        "path = kagglehub.dataset_download(\"rupankarmajumdar/crop-pests-dataset\")      # Getting the DATASET from kagglehub via CLI API (see their website - DON'T CHANGE)\n",
        "\n",
        "local_path = pathlib.Path(\"/content/datasets/crop-pests\")     # Saved the images to a local path to increase efficiency\n",
        "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "shutil.copytree(path, local_path, dirs_exist_ok=True)\n",
        "\n",
        "data_yaml_path = local_path / \"data.yaml\"     # YAML CONGIF (DON'T CHANGE)\n",
        "data_cfg = {\n",
        "    \"path\": str(local_path),\n",
        "    \"train\": \"train/images\",\n",
        "    \"val\":   \"valid/images\",\n",
        "    \"test\":  \"test/images\",\n",
        "    \"nc\": 12,\n",
        "    \"names\":\n",
        "     [\n",
        "      \"Ants\",\n",
        "      \"Bees\",\n",
        "      \"Beetles\",\n",
        "      \"Catterpillars\",     # NOTE: HAD TO CHANGE SPELLING BECAUSE DATASET IMAGES ARE SPELT LIKE THIS\n",
        "      \"Earthworms\",\n",
        "      \"Earwigs\",\n",
        "      \"Grasshoppers\",\n",
        "      \"Moths\",\n",
        "      \"Slugs\",\n",
        "      \"Snails\",\n",
        "      \"Wasps\",\n",
        "      \"Weevils\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    yaml.safe_dump(data_cfg, f)\n",
        "\n",
        "\n",
        "# CHECKS\n",
        "num_train_images = len(list((local_path / \"train\" / \"images\").glob(\"*.jpg\")))\n",
        "num_val_images = len(list((local_path / \"valid\" / \"images\").glob(\"*.jpg\")))\n",
        "num_test_images = len(list((local_path / \"test\" / \"images\").glob(\"*.jpg\")))\n",
        "\n",
        "num_train_labels = len(list((local_path / \"train\" / \"labels\").glob(\"*.txt\")))\n",
        "num_val_labels = len(list((local_path / \"valid\" / \"labels\").glob(\"*.txt\")))\n",
        "num_test_labels = len(list((local_path / \"test\" / \"labels\").glob(\"*.txt\")))\n",
        "\n",
        "print(f\"Number of training images: {num_train_images}\")\n",
        "print(f\"Number of validation images: {num_val_images}\")\n",
        "print(f\"Number of test images: {num_test_images}\")\n",
        "print(f\"Number of training labels: {num_train_labels}\")\n",
        "print(f\"Number of validation labels: {num_val_labels}\")\n",
        "print(f\"Number of test labels: {num_test_labels}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkuLvvScTcpn"
      },
      "source": [
        "# **Our Evaluation Metrics**\n",
        "- mAP@0.5 >= 0.5\n",
        "- mAP@0.5:0.95 (elps you detect over/under-sized bounding boxes)\n",
        "- Precision (false positive control)\n",
        "- Recall (false negative control)\n",
        "- F1 score\n",
        "- Training and Testing times\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I0w3De9jVddK"
      },
      "outputs": [],
      "source": [
        "def base_evaluation_metrics(val_results):\n",
        "    metrics = val_results.results_dict\n",
        "    precision = metrics.get('metrics/precision(B)', 0)\n",
        "    recall    = metrics.get('metrics/recall(B)', 0)\n",
        "    mAP50     = metrics.get('metrics/mAP50(B)', 0)\n",
        "    mAP50_95  = metrics.get('metrics/mAP50-95(B)', 0)\n",
        "    f1_score  = (2 * precision * recall) / (precision + recall) if (precision + recall) else 0\n",
        "    print(f\"\\nMean Average Precision (mAP@0.5):        {mAP50:.4f}\")\n",
        "    print(f\"Mean Average Precision (mAP@0.5:0.95):   {mAP50_95:.4f}\")\n",
        "    print(f\"Precision: {precision:.4f}  |  Recall: {recall:.4f}  |  F1-score: {f1_score:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E9-hASZH932E"
      },
      "outputs": [],
      "source": [
        "def format_time(seconds):\n",
        "    mins, secs = divmod(seconds, 60)      # Converts total seconds into minutes and format.\n",
        "    return f\"{int(mins):0d}m {secs:.2f}s\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q_k9rux2zWPK"
      },
      "source": [
        "# Minority Class Duplication and Augmentation\n",
        "--------------------------------------------------------\n",
        "- rotating by 180 degress\n",
        "- adding salt and pepper noise\n",
        "- Mosaic:1\n",
        "- Resolution: 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H-_sWrmuJNt8"
      },
      "outputs": [],
      "source": [
        "local_path = Path(\"/content/datasets/crop-pests\")     # Ensure local_path and names are defined\n",
        "data_yaml = yaml.safe_load(open(local_path / \"data.yaml\"))\n",
        "names = data_yaml[\"names\"]\n",
        "\n",
        "minority_classes = [\"Slugs\", \"Earthworms\", \"Beetles\", \"Catterpillars\", \"Earwigs\"]\n",
        "\n",
        "MAX_DUPLICATES = 1000\n",
        "SP_AMOUNT = 0.05\n",
        "SP_SALT_VS_PEPPER = 0.5\n",
        "\n",
        "\n",
        "def add_salt_and_pepper_noise(img, amount=0.05, salt_vs_pepper=0.5):\n",
        "    noisy = img.copy()\n",
        "    h, w = noisy.shape[:2]\n",
        "    num_pixels = h * w\n",
        "    num_salt = int(amount * num_pixels * salt_vs_pepper)\n",
        "    num_pepper = int(amount * num_pixels * (1 - salt_vs_pepper))\n",
        "\n",
        "    # Salt (white) noise\n",
        "    ys = np.random.randint(0, h, num_salt)\n",
        "    xs = np.random.randint(0, w, num_salt)\n",
        "    noisy[ys, xs] = 255\n",
        "\n",
        "    # Pepper (black) noise\n",
        "    ys = np.random.randint(0, h, num_pepper)\n",
        "    xs = np.random.randint(0, w, num_pepper)\n",
        "    noisy[ys, xs] = 0\n",
        "\n",
        "    return noisy\n",
        "\n",
        "\n",
        "minority_class_ids = [names.index(c) for c in minority_classes if c in names]     # Get the class IDs for minority classes\n",
        "\n",
        "duplicated_count = 0      # make sure this exists even if no minority classes\n",
        "\n",
        "if not minority_class_ids:\n",
        "    print(\"No valid minority classes specified from the dataset names.\")\n",
        "else:\n",
        "    print(f\"Minority classes for duplication: {minority_classes}\")\n",
        "\n",
        "    train_images_dir = local_path / \"train\" / \"images\"\n",
        "    train_labels_dir = local_path / \"train\" / \"labels\"\n",
        "\n",
        "    # Create directories for duplicated images and labels\n",
        "    duplicated_images_dir = local_path / \"train\" / \"images_duplicated\"\n",
        "    duplicated_labels_dir = local_path / \"train\" / \"labels_duplicated\"\n",
        "\n",
        "    # Clean up previous runs if any\n",
        "    if duplicated_images_dir.exists():\n",
        "        shutil.rmtree(duplicated_images_dir)\n",
        "    if duplicated_labels_dir.exists():\n",
        "        shutil.rmtree(duplicated_labels_dir)\n",
        "\n",
        "    duplicated_images_dir.mkdir(parents=True, exist_ok=True)\n",
        "    duplicated_labels_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    processed_images_count = 0\n",
        "\n",
        "    for label_file in train_labels_dir.glob(\"*.txt\"):\n",
        "        if duplicated_count >= MAX_DUPLICATES:    # Stop once we hit duplicates limit\n",
        "            break\n",
        "\n",
        "        image_file = train_images_dir / f\"{label_file.stem}.jpg\"\n",
        "        if not image_file.exists():\n",
        "            continue\n",
        "\n",
        "        has_minority_class = False\n",
        "        try:\n",
        "            with open(label_file, 'r') as f:\n",
        "                for line in f:\n",
        "                    parts = line.strip().split()\n",
        "                    if parts:\n",
        "                        class_id = int(parts[0])\n",
        "                        if class_id in minority_class_ids:\n",
        "                            has_minority_class = True\n",
        "                            break     # Found a minority class\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading label file {label_file}: {e}\")\n",
        "            continue      # Skip this file if there's an error\n",
        "\n",
        "        if has_minority_class:\n",
        "            processed_images_count += 1\n",
        "\n",
        "            new_image_name = f\"{image_file.stem}_dup{1}{image_file.suffix}\"\n",
        "            new_label_name = f\"{label_file.stem}_dup{1}{label_file.suffix}\"\n",
        "\n",
        "            new_image_path = duplicated_images_dir / new_image_name\n",
        "            new_label_path = duplicated_labels_dir / new_label_name\n",
        "\n",
        "            try:\n",
        "                img = cv2.imread(str(image_file))     # Read original image\n",
        "                if img is None:\n",
        "                    print(f\"Warning: Could not read image {image_file} for augmentation.\")\n",
        "                    continue\n",
        "\n",
        "                noisy_img = add_salt_and_pepper_noise(      # 1) Add salt-and-pepper noise\n",
        "                    img,\n",
        "                    amount=SP_AMOUNT,\n",
        "                    salt_vs_pepper=SP_SALT_VS_PEPPER\n",
        "                )\n",
        "\n",
        "                rotated_img = cv2.rotate(noisy_img, cv2.ROTATE_180)     # 2) Rotate 180 degrees\n",
        "\n",
        "\n",
        "                cv2.imwrite(str(new_image_path), rotated_img)\n",
        "                shutil.copy2(str(label_file), str(new_label_path))      # NOTE: Duplicate label file (no change to coords)\n",
        "\n",
        "                duplicated_count += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error duplicating files for {image_file}: {e}\")\n",
        "\n",
        "print(f\"Total Duplicates: {duplicated_count}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0c9760e"
      },
      "outputs": [],
      "source": [
        "# Generate Training File List Including Duplicated Images (No Copying)\n",
        "\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "\n",
        "original_train_images_dir = local_path / \"train\" / \"images\"\n",
        "duplicated_images_dir = local_path / \"train\" / \"images_duplicated\"      # This is for duplicates\n",
        "\n",
        "train_file_list_path = local_path / \"train_images_list.txt\"\n",
        "\n",
        "all_train_image_paths = []\n",
        "\n",
        "if original_train_images_dir.exists():\n",
        "    print(f\"Collecting images from: {original_train_images_dir}\")\n",
        "    all_train_image_paths.extend([str(p.resolve()) for p in original_train_images_dir.glob(\"*.jpg\")])     # Collect original image paths\n",
        "else:\n",
        "    print(f\"Warning: Original training images directory not found at {original_train_images_dir}\")\n",
        "\n",
        "\n",
        "if duplicated_images_dir.exists():\n",
        "    print(f\"Collecting images from: {duplicated_images_dir}\")\n",
        "    all_train_image_paths.extend([str(p.resolve()) for p in duplicated_images_dir.glob(\"*.jpg\")])     # Collect duplicated image paths\n",
        "else:\n",
        "    print(f\"Warning: Duplicated images directory not found at {duplicated_images_dir}\")\n",
        "\n",
        "\n",
        "with open(train_file_list_path, \"w\") as f:\n",
        "    for img_path in all_train_image_paths:      # Write the file list to a text file\n",
        "        f.write(f\"{img_path}\\n\")\n",
        "\n",
        "print(f\"\\nGenerated training image file list at: {train_file_list_path}\")\n",
        "print(f\"Total images included in the file list: {len(all_train_image_paths)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "62349667"
      },
      "outputs": [],
      "source": [
        "# Update data.yaml to Use the Training File List\n",
        "\n",
        "data_yaml_path = local_path / \"data.yaml\"\n",
        "\n",
        "\n",
        "if data_yaml_path.exists():     # Load the existing data.yaml content\n",
        "    with open(data_yaml_path, \"r\") as f:\n",
        "        data_cfg = yaml.safe_load(f)\n",
        "else:\n",
        "    print(f\"Warning: data.yaml not found at {data_yaml_path}. Creating a new one.\")\n",
        "    data_cfg = {\n",
        "        \"path\": str(local_path), # Keep the root path for val/test\n",
        "        \"val\":   \"valid/images\",\n",
        "        \"test\":  \"test/images\",\n",
        "        \"nc\": 12,\n",
        "        \"names\":\n",
        "         [\n",
        "          \"Ants\",\n",
        "          \"Bees\",\n",
        "          \"Beetles\",\n",
        "          \"Catterpillars\",\n",
        "          \"Earthworms\",\n",
        "          \"Earwigs\",\n",
        "          \"Grasshoppers\",\n",
        "          \"Moths\",\n",
        "          \"Slugs\",\n",
        "          \"Snails\",\n",
        "          \"Wasps\",\n",
        "          \"Weevils\",\n",
        "        ]\n",
        "    }\n",
        "\n",
        "data_cfg[\"train\"] = str(train_file_list_path.resolve())\n",
        "\n",
        "\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    yaml.safe_dump(data_cfg, f)     # Write the updated data.yaml file\n",
        "\n",
        "\n",
        "print(yaml.safe_dump(data_cfg))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ECyuhmJGrTkz"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n",
        "start = time.time()\n",
        "train_res = model.train(\n",
        "    data=str(local_path/\"data.yaml\"),     # Use the data.yaml file which now points to the training image file list\n",
        "    epochs=10,\n",
        "    imgsz=512,\n",
        "    mosaic=1.0,\n",
        "    batch=-1,\n",
        "    device=0,\n",
        "    project=\"pests_fast\",\n",
        "    name=\"yolov8n_colab\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "train_time = end - start\n",
        "\n",
        "start = time.time()\n",
        "val_results = model.val(\n",
        "    data=str(local_path/\"data.yaml\"),\n",
        "    split=\"val\",\n",
        "    batch=16,\n",
        "    iou=0.5,\n",
        "    device=0,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "val_time = end - start\n",
        "\n",
        "base_evaluation_metrics(val_results)\n",
        "print(f\"Training Time (Total): {format_time(train_time)}\")\n",
        "print(f\"Testing/Validation Time (Total): {format_time(val_time)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Joc-_BPJU-9"
      },
      "source": [
        "Mean Average Precision (mAP@0.5):        0.7411\n",
        "Mean Average Precision (mAP@0.5:0.95):   0.4088\n",
        "Precision: 0.7706  |  Recall: 0.7064  |  F1-score: 0.7371\n",
        "Training Time (Total): 5m 43.07s\n",
        "Testing/Validation Time (Total): 0m 8.95s"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JxaRNjcsKTPb"
      },
      "source": [
        "# Epoch Optimising\n",
        "------------------------------------------\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ctWrJFGKKzmE"
      },
      "outputs": [],
      "source": [
        "model = YOLO(\"yolov8n.pt\")\n",
        "start = time.time()\n",
        "train_res = model.train(\n",
        "    data=str(local_path/\"data.yaml\"),     # Use the data.yaml file which now points to the training image file list\n",
        "    epochs=50,\n",
        "    imgsz=512,\n",
        "    mosaic=1.0,\n",
        "    batch=-1,\n",
        "    device=0,\n",
        "    project=\"pests_fast\",\n",
        "    name=\"yolov8n_colab\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "train_time = end - start\n",
        "\n",
        "start = time.time()\n",
        "val_results = model.val(\n",
        "    data=str(local_path/\"data.yaml\"),\n",
        "    split=\"val\",\n",
        "    batch=16,\n",
        "    iou=0.5,\n",
        "    device=0,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "val_time = end - start\n",
        "\n",
        "base_evaluation_metrics(val_results)\n",
        "print(f\"Training Time (Total): {format_time(train_time)}\")\n",
        "print(f\"Testing/Validation Time (Total): {format_time(val_time)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZdssWS_f2dLv"
      },
      "outputs": [],
      "source": [
        "results_csv_path = Path(train_res.save_dir) / \"results.csv\"     # Dynamically construct the path to results.csv using the save_dir from the training run\n",
        "\n",
        "\n",
        "if results_csv_path.exists():     # Check if the file exists before attempting to read it\n",
        "    df = pd.read_csv(results_csv_path)\n",
        "\n",
        "    plt.figure(figsize=(8,4))\n",
        "    plt.plot(df[\"train/box_loss\"], label=\"Train Box Loss\")\n",
        "    plt.plot(df[\"val/box_loss\"], label=\"Val Box Loss\")\n",
        "    plt.legend()\n",
        "    plt.xlabel(\"Epoch\")\n",
        "    plt.ylabel(\"Loss\")\n",
        "    plt.title(f\"YOLOv8 Training vs Validation Loss\")\n",
        "    plt.grid(True)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(f\"Error: results.csv not found at {results_csv_path}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baKqHF97AicX"
      },
      "source": [
        "# Final Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMvnELKXAkWj"
      },
      "outputs": [],
      "source": [
        "# OPTIMISED 10 EPOCH\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "start = time.time()\n",
        "train_res = model.train(\n",
        "    data=str(local_path/\"data.yaml\"),     # Use the data.yaml file which now points to the training image file list\n",
        "    epochs=10,\n",
        "    imgsz=512,\n",
        "    mosaic=0.0,\n",
        "    batch=-1,\n",
        "    device=0,\n",
        "    project=\"pests_fast\",\n",
        "    name=\"yolov8n_colab\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "train_time = end - start\n",
        "\n",
        "start = time.time()\n",
        "val_results = model.val(\n",
        "    data=str(local_path/\"data.yaml\"),\n",
        "    split=\"test\",\n",
        "    batch=16,\n",
        "    iou=0.5,\n",
        "    device=0,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "val_time = end - start\n",
        "\n",
        "base_evaluation_metrics(val_results)\n",
        "print(f\"Training Time (Total): {format_time(train_time)}\")\n",
        "print(f\"Testing/Validation Time (Total): {format_time(val_time)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JLsEtj1rA46M"
      },
      "outputs": [],
      "source": [
        "# OPTIMISED 15 EPOCH: CHOSEN\n",
        "model = YOLO(\"yolov8n.pt\")\n",
        "start = time.time()\n",
        "train_res = model.train(\n",
        "    data=str(local_path/\"data.yaml\"),     # Use the data.yaml file which now points to the training image file list\n",
        "    epochs=15,\n",
        "    imgsz=512,\n",
        "    mosaic=1.0,\n",
        "    batch=-1,\n",
        "    device=0,\n",
        "    project=\"pests_fast\",\n",
        "    name=\"yolov8n_colab\",\n",
        "    verbose=True\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "train_time = end - start\n",
        "start = time.time()\n",
        "val_results = model.val(\n",
        "    data=str(local_path/\"data.yaml\"),\n",
        "    split=\"test\",\n",
        "    batch=16,\n",
        "    iou=0.5,\n",
        "    device=0,\n",
        "    workers=2\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "val_time = end - start\n",
        "\n",
        "base_evaluation_metrics(val_results)\n",
        "print(f\"Training Time (Total): {format_time(train_time)}\")\n",
        "print(f\"Testing/Validation Time (Total): {format_time(val_time)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qPOtbMVjBFQi"
      },
      "outputs": [],
      "source": [
        "# OPTIMISED TWO-LAYER YOLO\n",
        "base_p = pathlib.Path(\"/content\") if os.path.isdir(\"/content\") else pathlib.Path.cwd()\n",
        "cfg_p = local_path/\"data.yaml\"\n",
        "runs_p = base_p / \"yolo_runs\"\n",
        "runs_p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Aims to have strong aug, smaller resolution. Thus, learn robust features faster\n",
        "yolo_1 = YOLO(\"yolov8n.pt\")\n",
        "start = time.time()\n",
        "\n",
        "train_res_1 = yolo_1.train(\n",
        "    data=str(cfg_p),\n",
        "    epochs=15,\n",
        "    imgsz=256,\n",
        "    batch=8,\n",
        "    device=0,\n",
        "    workers=2,\n",
        "    project=str(runs_p),\n",
        "    name=\"cp_s1_mosaic\",\n",
        "    verbose=False,\n",
        "    mosaic=1.0\n",
        "\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "train_time = end - start\n",
        "\n",
        "start = time.time()\n",
        "val_results = yolo_1.val(\n",
        "    data=str(data_yaml_path),\n",
        "    split=\"test\",\n",
        "    batch=16,\n",
        "    device=0,\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "val_time = end - start\n",
        "\n",
        "base_evaluation_metrics(val_results)\n",
        "print(f\"Training Time (Total): {format_time(train_time)}\")\n",
        "print(f\"Testing/Validation Time (Total): {format_time(val_time)}\")\n",
        "\n",
        "\n",
        "# Aims to fine-tune from best.pt with realistic images\n",
        "best_1 = runs_p / \"cp_s1_mosaic\" / \"weights\" / \"best.pt\"\n",
        "\n",
        "yolo_2 = YOLO(str(best_1))\n",
        "\n",
        "start = time.time()\n",
        "train_res_2 = yolo_2.train(\n",
        "    data=str(local_path/\"data.yaml\"),\n",
        "    epochs=10,\n",
        "    imgsz=512,\n",
        "    batch=8,\n",
        "    device=0,\n",
        "    workers=2,\n",
        "    project=str(runs_p),\n",
        "    name=\"cp_s2_nomosaic\",\n",
        "    verbose=False,\n",
        "    mosaic=0.0    # Changed\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "train_time = end - start\n",
        "\n",
        "start = time.time()\n",
        "val_results = yolo_2.val(\n",
        "    data=str(data_yaml_path),\n",
        "    split=\"test\",\n",
        "    batch=16,\n",
        "    device=0,\n",
        ")\n",
        "\n",
        "end = time.time()\n",
        "val_time = end - start\n",
        "\n",
        "base_evaluation_metrics(val_results)\n",
        "print(f\"Training Time (Total): {format_time(train_time)}\")\n",
        "print(f\"Testing/Validation Time (Total): {format_time(val_time)}\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
