{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2vSW08991nB-",
        "outputId": "208e680a-9aa1-4574-d0cb-bcbbf8c39b6e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m32.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for efficientnet_pytorch (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Creating new Ultralytics Settings v0.0.6 file âœ… \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n",
            "Using Colab cache for faster access to the 'crop-pests-dataset' dataset.\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8n.pt to 'yolov8n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 6.2MB 242.0MB/s 0.0s\n",
            "Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/datasets/crop-pests/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=10, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=yolov8n.pt, momentum=0.937, mosaic=0.5, multi_scale=False, name=cp_s1_mosaic, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/yolo_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/yolo_runs/cp_s1_mosaic, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "\u001b[KDownloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf': 100% â”â”â”â”â”â”â”â”â”â”â”â” 755.1KB 101.2MB/s 0.0s\n",
            "Overriding model.yaml nc=80 with nc=12\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753652  ultralytics.nn.modules.head.Detect           [12, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,013,188 parameters, 3,013,172 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 319/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[KDownloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolo11n.pt to 'yolo11n.pt': 100% â”â”â”â”â”â”â”â”â”â”â”â” 5.4MB 263.6MB/s 0.0s\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1192.9Â±321.8 MB/s, size: 47.0 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/crop-pests/train/labels... 11502 images, 3 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11502/11502 2.5Kit/s 4.6s\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/datasets/crop-pests/train/labels.cache\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 401.2Â±107.9 MB/s, size: 34.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/crop-pests/valid/labels... 1095 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1095/1095 903.8it/s 1.2s\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/datasets/crop-pests/valid/labels.cache\n",
            "Plotting labels to /content/yolo_runs/cp_s1_mosaic/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolo_runs/cp_s1_mosaic\u001b[0m\n",
            "Starting training for 10 epochs...\n",
            "Closing dataloader mosaic\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       1/10      1.21G      1.559      3.613       2.11          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.5it/s 3:41\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 7.0it/s 9.9s\n",
            "                   all       1095       1341      0.401      0.478       0.43      0.212\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       2/10      1.41G      1.556      2.524      2.052          7        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.9it/s 3:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 8.0it/s 8.6s\n",
            "                   all       1095       1341      0.511      0.477      0.505      0.265\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       3/10      1.43G      1.553      2.135      2.043          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.9it/s 3:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 8.9it/s 7.7s\n",
            "                   all       1095       1341       0.57      0.473        0.5      0.262\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       4/10      1.45G       1.51      1.894      1.997          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.9it/s 3:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 9.0it/s 7.7s\n",
            "                   all       1095       1341       0.64      0.558        0.6      0.331\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       5/10      1.47G      1.465      1.705      1.949          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.9it/s 3:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 8.0it/s 8.7s\n",
            "                   all       1095       1341       0.71      0.591       0.64      0.363\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       6/10      1.48G      1.422      1.535      1.907          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.9it/s 3:29\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 8.0it/s 8.6s\n",
            "                   all       1095       1341      0.724      0.626      0.677      0.374\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       7/10       1.5G      1.378      1.401      1.864          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.9it/s 3:28\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 8.2it/s 8.5s\n",
            "                   all       1095       1341      0.763      0.635      0.702      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       8/10      1.52G      1.332       1.29      1.821          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 7.0it/s 3:25\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 9.0it/s 7.7s\n",
            "                   all       1095       1341      0.733      0.663      0.713      0.406\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K       9/10      1.53G      1.285       1.18      1.773          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.9it/s 3:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 9.1it/s 7.6s\n",
            "                   all       1095       1341      0.737      0.674      0.717      0.413\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K      10/10      1.55G       1.25      1.102      1.743         13        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.9it/s 3:27\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 8.3it/s 8.3s\n",
            "                   all       1095       1341      0.808      0.683      0.747      0.428\n",
            "\n",
            "10 epochs completed in 0.604 hours.\n",
            "Optimizer stripped from /content/yolo_runs/cp_s1_mosaic/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/yolo_runs/cp_s1_mosaic/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/yolo_runs/cp_s1_mosaic/weights/best.pt...\n",
            "Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,007,988 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 7.1it/s 9.7s\n",
            "                   all       1095       1341      0.809      0.683      0.747      0.428\n",
            "Speed: 0.2ms preprocess, 2.3ms inference, 0.0ms loss, 1.8ms postprocess per image\n",
            "Results saved to \u001b[1m/content/yolo_runs/cp_s1_mosaic\u001b[0m\n",
            "Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,007,988 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1618.9Â±512.5 MB/s, size: 40.4 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/crop-pests/valid/labels.cache... 1095 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1095/1095 2.1Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 6.2it/s 11.1s\n",
            "                   all       1095       1341      0.807      0.683      0.747      0.427\n",
            "                  Ants         96        178      0.735      0.591      0.651      0.255\n",
            "                  Bees         99        110      0.921        0.8      0.857      0.377\n",
            "               Beetles         89        100       0.61       0.58      0.584      0.276\n",
            "         Catterpillars         77        139      0.715      0.374      0.447      0.237\n",
            "            Earthworms         53         72       0.57      0.361        0.4      0.198\n",
            "               Earwigs         91        104      0.849      0.692      0.786      0.422\n",
            "          Grasshoppers         98        102      0.797      0.654      0.768      0.386\n",
            "                 Moths        100        101      0.959      0.911      0.981      0.742\n",
            "                 Slugs         77         91      0.697      0.531      0.645      0.384\n",
            "                Snails         99        107       0.91      0.916      0.968      0.638\n",
            "                 Wasps        116        132      0.974      0.842      0.917      0.568\n",
            "               Weevils        104        105      0.952      0.942      0.962      0.641\n",
            "Speed: 1.5ms preprocess, 3.9ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val\u001b[0m\n",
            "Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0magnostic_nms=False, amp=True, augment=False, auto_augment=randaugment, batch=8, bgr=0.0, box=7.5, cache=False, cfg=None, classes=None, close_mosaic=10, cls=0.5, compile=False, conf=None, copy_paste=0.0, copy_paste_mode=flip, cos_lr=False, cutmix=0.0, data=/content/datasets/crop-pests/data.yaml, degrees=0.0, deterministic=True, device=0, dfl=1.5, dnn=False, dropout=0.0, dynamic=False, embed=None, epochs=5, erasing=0.4, exist_ok=False, fliplr=0.5, flipud=0.0, format=torchscript, fraction=1.0, freeze=None, half=False, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, imgsz=640, int8=False, iou=0.7, keras=False, kobj=1.0, line_width=None, lr0=0.01, lrf=0.01, mask_ratio=4, max_det=300, mixup=0.0, mode=train, model=/content/yolo_runs/cp_s1_mosaic/weights/best.pt, momentum=0.937, mosaic=0.0, multi_scale=False, name=cp_s2_nomosaic, nbs=64, nms=False, opset=None, optimize=False, optimizer=auto, overlap_mask=True, patience=100, perspective=0.0, plots=True, pose=12.0, pretrained=True, profile=False, project=/content/yolo_runs, rect=False, resume=False, retina_masks=False, save=True, save_conf=False, save_crop=False, save_dir=/content/yolo_runs/cp_s2_nomosaic, save_frames=False, save_json=False, save_period=-1, save_txt=False, scale=0.5, seed=0, shear=0.0, show=False, show_boxes=True, show_conf=True, show_labels=True, simplify=True, single_cls=False, source=None, split=val, stream_buffer=False, task=detect, time=None, tracker=botsort.yaml, translate=0.1, val=True, verbose=False, vid_stride=1, visualize=False, warmup_bias_lr=0.1, warmup_epochs=3.0, warmup_momentum=0.8, weight_decay=0.0005, workers=2, workspace=None\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
            "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
            "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
            "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
            "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
            "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
            "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
            "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
            " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
            " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
            " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
            " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
            " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
            " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
            " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
            " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
            " 22        [15, 18, 21]  1    753652  ultralytics.nn.modules.head.Detect           [12, [64, 128, 256]]          \n",
            "Model summary: 129 layers, 3,013,188 parameters, 3,013,172 gradients, 8.2 GFLOPs\n",
            "\n",
            "Transferred 355/355 items from pretrained weights\n",
            "Freezing layer 'model.22.dfl.conv.weight'\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1716.2Â±538.7 MB/s, size: 51.1 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/datasets/crop-pests/train/labels.cache... 11502 images, 3 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 11502/11502 16.4Mit/s 0.0s\n",
            "\u001b[34m\u001b[1malbumentations: \u001b[0mBlur(p=0.01, blur_limit=(3, 7)), MedianBlur(p=0.01, blur_limit=(3, 7)), ToGray(p=0.01, method='weighted_average', num_output_channels=3), CLAHE(p=0.01, clip_limit=(1.0, 4.0), tile_grid_size=(8, 8))\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 413.9Â±96.5 MB/s, size: 36.6 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/crop-pests/valid/labels.cache... 1095 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1095/1095 380.7Kit/s 0.0s\n",
            "Plotting labels to /content/yolo_runs/cp_s2_nomosaic/labels.jpg... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000625, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
            "Image sizes 640 train, 640 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1m/content/yolo_runs/cp_s2_nomosaic\u001b[0m\n",
            "Starting training for 5 epochs...\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        1/5      1.18G      1.274       1.14      1.762          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.4it/s 3:44\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 8.0it/s 8.7s\n",
            "                   all       1095       1341      0.761      0.632      0.697      0.391\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        2/5      1.18G      1.344      1.249       1.82          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.7it/s 3:35\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 7.9it/s 8.7s\n",
            "                   all       1095       1341       0.66      0.629      0.641      0.355\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        3/5      1.18G      1.338      1.248      1.821          8        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.8it/s 3:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 8.6it/s 8.0s\n",
            "                   all       1095       1341      0.744      0.666      0.698      0.398\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        4/5      1.18G      1.294      1.135      1.778          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.7it/s 3:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 8.6it/s 8.0s\n",
            "                   all       1095       1341       0.75      0.652      0.709      0.401\n",
            "\n",
            "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n",
            "\u001b[K        5/5      1.18G      1.234      1.007      1.718          6        640: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1438/1438 6.7it/s 3:33\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 8.8it/s 7.9s\n",
            "                   all       1095       1341      0.775      0.697      0.747      0.436\n",
            "\n",
            "5 epochs completed in 0.311 hours.\n",
            "Optimizer stripped from /content/yolo_runs/cp_s2_nomosaic/weights/last.pt, 6.2MB\n",
            "Optimizer stripped from /content/yolo_runs/cp_s2_nomosaic/weights/best.pt, 6.2MB\n",
            "\n",
            "Validating /content/yolo_runs/cp_s2_nomosaic/weights/best.pt...\n",
            "Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,007,988 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 6.9it/s 10.0s\n",
            "                   all       1095       1341      0.774      0.697      0.747      0.437\n",
            "Speed: 0.3ms preprocess, 2.4ms inference, 0.0ms loss, 1.9ms postprocess per image\n",
            "Results saved to \u001b[1m/content/yolo_runs/cp_s2_nomosaic\u001b[0m\n",
            "Ultralytics 8.3.228 ğŸš€ Python-3.12.12 torch-2.8.0+cu126 CUDA:0 (Tesla T4, 15095MiB)\n",
            "Model summary (fused): 72 layers, 3,007,988 parameters, 0 gradients, 8.1 GFLOPs\n",
            "\u001b[34m\u001b[1mval: \u001b[0mFast image access âœ… (ping: 0.0Â±0.0 ms, read: 1295.9Â±489.5 MB/s, size: 36.9 KB)\n",
            "\u001b[K\u001b[34m\u001b[1mval: \u001b[0mScanning /content/datasets/crop-pests/valid/labels.cache... 1095 images, 0 backgrounds, 0 corrupt: 100% â”â”â”â”â”â”â”â”â”â”â”â” 1095/1095 2.3Mit/s 0.0s\n",
            "\u001b[K                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% â”â”â”â”â”â”â”â”â”â”â”â” 69/69 6.1it/s 11.3s\n",
            "                   all       1095       1341      0.777      0.696      0.747      0.436\n",
            "                  Ants         96        178      0.812      0.511      0.655      0.258\n",
            "                  Bees         99        110      0.871      0.798      0.849      0.386\n",
            "               Beetles         89        100      0.556       0.57      0.557      0.267\n",
            "         Catterpillars         77        139      0.707      0.417      0.473      0.234\n",
            "            Earthworms         53         72      0.611      0.431      0.464      0.254\n",
            "               Earwigs         91        104      0.738      0.692      0.763      0.442\n",
            "          Grasshoppers         98        102      0.729      0.686      0.722      0.382\n",
            "                 Moths        100        101      0.871      0.933      0.969      0.747\n",
            "                 Slugs         77         91      0.637      0.593      0.652      0.387\n",
            "                Snails         99        107      0.895      0.935      0.972      0.649\n",
            "                 Wasps        116        132      0.957      0.864      0.916      0.587\n",
            "               Weevils        104        105      0.946      0.924      0.972      0.639\n",
            "Speed: 1.9ms preprocess, 3.8ms inference, 0.0ms loss, 1.3ms postprocess per image\n",
            "Results saved to \u001b[1m/content/runs/detect/val2\u001b[0m\n",
            "Stage 1 Results\n",
            "Overall: {'mAP50-95(B)': 0.427, 'precision(B)': 0.8073, 'recall(B)': 0.6828}\n",
            "Per-class mAP50-95:\n",
            "  Ants: 0.2548\n",
            "  Bees: 0.3770\n",
            "  Beetles: 0.2763\n",
            "  Catterpillars: 0.2365\n",
            "  Earthworms: 0.1981\n",
            "  Earwigs: 0.4217\n",
            "  Grasshoppers: 0.3858\n",
            "  Moths: 0.7415\n",
            "  Slugs: 0.3844\n",
            "  Snails: 0.6383\n",
            "  Wasps: 0.5681\n",
            "  Weevils: 0.6412\n",
            "Stage 2 Results\n",
            "Overall: {'mAP50-95(B)': 0.4361, 'precision(B)': 0.7774, 'recall(B)': 0.6961}\n"
          ]
        }
      ],
      "source": [
        "%pip install -q ultralytics kagglehub pyyaml opencv-python efficientnet_pytorch torch torchvision\n",
        "\n",
        "import os\n",
        "import shutil\n",
        "import pathlib\n",
        "import yaml\n",
        "import cv2\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.transforms as T\n",
        "from torchvision.datasets import ImageFolder\n",
        "\n",
        "import kagglehub\n",
        "from ultralytics import YOLO\n",
        "from efficientnet_pytorch import EfficientNet\n",
        "\n",
        "#**********************************************\n",
        "base_p = pathlib.Path(\"/content\") if os.path.isdir(\"/content\") else pathlib.Path.cwd()\n",
        "path = kagglehub.dataset_download(\"rupankarmajumdar/crop-pests-dataset\")\n",
        "\n",
        "local_path = pathlib.Path(\"/content/datasets/crop-pests\")\n",
        "local_path.parent.mkdir(parents=True, exist_ok=True)\n",
        "shutil.copytree(path, local_path, dirs_exist_ok=True)\n",
        "\n",
        "data_yaml_path = local_path / \"data.yaml\"\n",
        "data_cfg = {\n",
        "    \"path\": str(local_path),\n",
        "    \"train\": \"train/images\",\n",
        "    \"val\":   \"valid/images\",\n",
        "    \"test\":  \"test/images\",\n",
        "    \"names\":\n",
        "     [\n",
        "      \"Ants\",\n",
        "      \"Bees\",\n",
        "      \"Beetles\",\n",
        "      \"Catterpillars\",\n",
        "      \"Earthworms\",\n",
        "      \"Earwigs\",\n",
        "      \"Grasshoppers\",\n",
        "      \"Moths\",\n",
        "      \"Slugs\",\n",
        "      \"Snails\",\n",
        "      \"Wasps\",\n",
        "      \"Weevils\",\n",
        "    ]\n",
        "}\n",
        "\n",
        "with open(data_yaml_path, \"w\") as f:\n",
        "    yaml.safe_dump(data_cfg, f)\n",
        "#**********************************************\n",
        "\n",
        "\n",
        "cfg_p = data_yaml_path\n",
        "runs_p = base_p / \"yolo_runs\"\n",
        "runs_p.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "yolo_1 = YOLO(\"yolov8n.pt\")\n",
        "\n",
        "yolo_1.train(\n",
        "    data=str(cfg_p),\n",
        "    epochs=10,\n",
        "    imgsz=640,\n",
        "    batch=8,\n",
        "    device=0,\n",
        "    workers=2,\n",
        "    project=str(runs_p),\n",
        "    name=\"cp_s1_mosaic\",\n",
        "    verbose=False,\n",
        "    mosaic=0.5,\n",
        "    mixup=0.0,\n",
        "    copy_paste=0.0,\n",
        ")\n",
        "#**********************************************\n",
        "\n",
        "v1 = yolo_1.val()\n",
        "\n",
        "box1 = v1.box\n",
        "names1 = v1.names\n",
        "\n",
        "m1_map = float(box1.map)\n",
        "m1_prec = float(box1.mp)\n",
        "m1_rec = float(box1.mr)\n",
        "\n",
        "per_class_map1 = {}\n",
        "if box1.maps is not None:\n",
        "    for cid, cname in names1.items():\n",
        "        if cid < len(box1.maps):\n",
        "            per_class_map1[cname] = float(box1.maps[cid])\n",
        "\n",
        "#**********************************************\n",
        "\n",
        "best_1 = runs_p / \"cp_s1_mosaic\" / \"weights\" / \"best.pt\"\n",
        "\n",
        "yolo_2 = YOLO(str(best_1))\n",
        "\n",
        "yolo_2.train(\n",
        "    data=str(cfg_p),\n",
        "    epochs=5,\n",
        "    imgsz=640,\n",
        "    batch=8,\n",
        "    device=0,\n",
        "    workers=2,\n",
        "    project=str(runs_p),\n",
        "    name=\"cp_s2_nomosaic\",\n",
        "    verbose=False,\n",
        "    mosaic=0.0,\n",
        "    mixup=0.0,\n",
        "    copy_paste=0.0,\n",
        ")\n",
        "\n",
        "v2 = yolo_2.val()\n",
        "\n",
        "box2 = v2.box\n",
        "names2 = v2.names\n",
        "\n",
        "m2_map  = float(box2.map)\n",
        "m2_prec = float(box2.mp)\n",
        "m2_rec  = float(box2.mr)\n",
        "\n",
        "per_class_map2 = {}\n",
        "if box2.maps is not None:\n",
        "    for cid, cname in names2.items():\n",
        "        if cid < len(box2.maps):\n",
        "            per_class_map2[cname] = float(box2.maps[cid])\n",
        "\n",
        "#**********************************************\n",
        "\n",
        "print(\"Stage 1 Results\")\n",
        "print(\"Overall:\", {\n",
        "    \"mAP50-95(B)\": round(m1_map, 4),\n",
        "    \"precision(B)\": round(m1_prec, 4),\n",
        "    \"recall(B)\": round(m1_rec, 4),\n",
        "})\n",
        "print(\"Per-class mAP50-95:\")\n",
        "for cls, score in per_class_map1.items():\n",
        "    print(f\"  {cls}: {score:.4f}\")\n",
        "\n",
        "print(\"Stage 2 Results\")\n",
        "print(\"Overall:\", {\n",
        "    \"mAP50-95(B)\": round(m2_map, 4),\n",
        "    \"precision(B)\": round(m2_prec, 4),\n",
        "    \"recall(B)\": round(m2_rec, 4),\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "j01qFNrC1oGO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
